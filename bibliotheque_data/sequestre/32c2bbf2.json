{
    "id": "32c2bbf2",
    "titre": "newbla",
    "auteur_nom": "blanew",
    "date_publication": "2025-12-13",
    "etat_classe": "EtatValidee",
    "contenu_markdown": "USENIX\nTHE ADVANCED COMPUTING\nSYSTEMS ASSOCIATION\nMy ZIP isn't your ZIP: Identifying and Exploiting\nSemantic Gaps Between ZIP Parsers\nYufan You, Tsinghua University; Jianjun Chen, Tsinghua University;\nZhongguancun Laboratory; Qi Wang, Tsinghua University;\nHaixin Duan, Tsinghua University; Zhongguancun Laboratory\nhttps://www.usenix.org/conference/usenixsecurity25/presentation/you\nThis paper is included in the Proceedings of the\n34th USENIX Security Symposium.\nAugust 13-15, 2025 • Seattle, WA, USA\n978-1-939133-52-6\nOpen access to the Proceedings of the\n34th USENIX Security Symposium is sponsored by USENIX.\n\nARTIFACT\nEVALUATED\nusenix\nASSOCIATION\nAVAILABLE\nMy ZIP isn't your ZIP: Identifying and Exploiting\nSemantic Gaps Between ZIP Parsers\nYufan You¹, Jianjun Chen1,2,✉, Qi Wang¹, and Haixin Duan1,2\n¹Tsinghua University\n²Zhongguancun Laboratory\n\nAbstract\nZIP is one of the most popular archive formats. It is used\nnot only as archive files, but also as the container for other file\nformats, including office documents, Android applications,\nJava archives, and many more. Despite its ubiquity, the ZIP\nfile format specification is imprecisely specified, posing the\nrisk of semantic gaps between implementations that can be\nexploited by attackers. While prior research has reported in-\ndividual such vulnerabilities, there is a lack of systematic\nstudies for ZIP parsing ambiguities.\nIn this paper, we developed a differential fuzzer ZIPDIFF\nand systematically identified parsing inconsistencies between\n50 ZIP parsers across 19 programming languages. The evalua-\ntion results show that almost all pairs of parsers are vulnerable\nto certain parsing ambiguities. We summarize our findings as\n14 distinct parsing ambiguity types in three categories with\ndetailed analysis, systematizing current knowledge and uncov-\nering 10 types of new parsing ambiguities. We demonstrate\nfive real-world scenarios where these parsing ambiguities\ncan be exploited, including bypassing secure email gateways,\nspoofing office document content, impersonating VS Code\nextensions, and tampering with signed nested JAR files while\nstill passing Spring Boot's signature verification. We further\npropose seven mitigation strategies to address these ambi-\nguities. We responsibly reported the vulnerabilities to the\naffected vendors and received positive feedback, including\nbounty rewards from Gmail, Coremail, and Zoho, and three\nCVEs from Go, LibreOffice, and Spring Boot.\n\n1 Introduction\nThe ZIP file format is one of the most popular archive formats.\nMost users recognize ZIP by its .zip file extension, but they\nare also using it implicitly, when they are reading and writing\noffice documents, installing Android applications and browser\nextensions, or running Java applications, because all these file\nformats use ZIP as the underlying container.\n\n✉Corresponding author: jianjun@tsinghua.edu.cn\nAs ZIP has become a fundamental building block in many\napplications, security researchers have been investigating the\nfile format to find potential vulnerabilities. Path traversal in\nZIP filenames, a.k.a. ZIP Slip [38], results in arbitrary file\nwriting that may escalate to remote code execution, while\nZIP bomb can be used to conduct DoS attacks by exhausting\ncomputing resources with highly compressed ZIP archives.\nMany ZIP libraries are deploying fuzz testing to uncover\nmemory bugs, including libzip, minizip, zip-rs, zip4j, zt-zip,\nand Commons Compress in OSS-Fuzz [6].\nThe work mentioned above all focused on individual ZIP\nparsers, while increasing attention from researchers is being\ndirected toward semantic gaps—subtle inconsistencies be-\ntween various ZIP implementations that can be exploited by\nattackers. A high-profile example is the infamous Android\nmaster key vulnerability [20], which bypassed Android's se-\ncurity by exploiting a mismatch between the ZIP component\nthat verifies signatures for privileged applications and the\ncomponent that decompresses the file contents. This discrep-\nancy allowed malicious code to be inserted into privileged\napplications without breaking their signatures. While individ-\nual vulnerabilities have been discovered [16, 20, 23], these\nstudies still rely on manual and ad hoc methods for discovery.\nTo date, no systematic study has yet been conducted for ZIP\nparsing ambiguities.\nIn this paper, we developed a differential fuzzing tool\nZIPDIFF. It generates and mutates ZIP files with grammar-\nbased rules and uses feedback from ZIP parsers to guide\nthe mutation. We collected 50 ZIP parsers across 19 pro-\ngramming languages and used ZIPDIFF to identify parsing\ninconsistencies between them. The results can be divided into\ntwo parts. First, we showed that parsing inconsistencies are\nquite prevalent among ZIP parsers nowadays, as almost any\npair of parsers is inconsistent in parsing ZIP files. Second,\nwe investigated the ZIP files that caused the discrepancies\nand classified these parsing ambiguities as 14 distinct types\nin three categories: redundant metadata, file path processing,\nand ZIP structure positioning. Many of these parsing ambigu-\nities were previously unknown, and we also uncovered new\n\nUSENIX Association\n34th USENIX Security Symposium 431\n\nvariants of known ambiguities and new techniques to bypass\ndetection of ambiguous ZIP files.\nWe demonstrate the practical impact of those parsing ambi-\nguities through five real-world exploitation scenarios: secure\nemail gateway bypass, office document content spoofing and\nsignature forgery, nested JAR signature forgery, and VS Code\nextension impersonation. These vulnerabilities affect a wide\nrange of critical applications, including Gmail, Golang, Spring\nBoot, and LibreOffice. We propose seven mitigation strategies\nto defend against those identified issues. We have reported our\nfindings to the affected vendors and coordinated in addressing\nthese issues. We received positive feedback including bounty\nrewards from Gmail, Coremail, and Zoho, and three CVEs\nfrom Go, LibreOffice, and Spring Boot.\nIn summary, we make the following contributions:\n• We designed and implemented our differential fuzzing\ntool ZIPDIFF¹ to systematically identify inconsistencies\nbetween ZIP parsers (Section 4).\n• We demonstrated the prevalence of discrepancies among\nZIP parsers through the evaluation of ZIPDIFF on 50\nparsers across 19 programming languages. We discov-\nered 14 distinct types of ZIP parsing ambiguities, of\nwhich 10 types are newly discovered (Section 5.2).\n• We proved the broad real-world impact of these discrep-\nancies by observing five attack scenarios where inconsis-\ntencies between ZIP parsers can be exploited (Section 6).\nWe have responsibly reported the identfied vulnerabili-\nties to the affected vendors (Section 7.1).\n• We proposed countermeasures to mitigate these attacks\nin various situations (Section 7.2).\n\n2 Background\n2.1 The ZIP File Format\nThe ZIP file format, originally created by PKWARE in 1989,\nis a widely used archive format specified in a document called\nAPPNOTE.txt [29]. Known for its popularity as an archive\nformat with the .zip file extension, ZIP also serves as a con-\ntainer for various other file types. These include office docu-\nment formats OOXML and ODF, Java Archive (JAR), PHP\nArchive (PHAR), Visual Studio Extension (VSIX), Android\nPackage (APK), Cross-Platform Install (XPI) used by Mozilla\nFirefox, Chrome Extension (CRX), and many more [15].\nA regular ZIP file includes three major parts, the local file\nentries, the central directory, and the end of central directory\nrecord, as illustrated in Fig. 1. Each of the local file entries\ncontains a Local File Header (LFH) and the compressed file\ndata, optionally with an encryption header and a data descrip-\ntor. The central directory consists of the Central Directory\nHeaders (CDHs), each pointing to an LFH. The CDHs and\n¹https://github.com/ouuan/ZipDiff\n\nLocal File Header 1\nEncryption Header 1 (optional)\nCompressed File Data 1\nData Descriptor 1 (optional)\nLocal File Header n\nEncryption Header n (optional)\nCompressed File Data n\nData Descriptor n (optional)\nCentral Directory\nCentral Directory Header 1\nCentral Directory Header n\nZIP64 End of Central Directory Record\nZIP64 End of Central Directory Locator\nEnd of Central Directory Record\nLocal File Header (LFH)\nLFH signature\nversion needed\nbit flags\ncompression method\nlast mod file time\nlast mod file date\ncrc-32\ncompressed size\nuncompressed size\nfile name length\nextra field length\nfile name\nextra field\n4 bytes\n2 bytes\n2 bytes\n2 bytes\n2 bytes\n2 bytes\n4 bytes\n4 bytes\n4 bytes\n2 bytes\n2 bytes\n(variable)\n(variable)\nCentral Directory Header (CDH)\nCDH signature\nversion made by\n(all fields in LFH...)\nfile comment length\ndisk number start\ninternal file attrs\nexternal file attrs\noffset to LFH\nfile comment\n4 bytes\n2 bytes\n2 bytes\n2 bytes\n4 bytes\n4 bytes\n(variable)\nEnd of Central Directory Record\nEOCDR signature\n4 bytes\n(central directory size\nand position information...)\nZIP comment length 2 bytes\nZIP comment\n(variable)\n\nFigure 1: Structure of the ZIP file format\n\nthe LFHs provide the metadata for the file entries, such as file-\nname, compression method, compressed and uncompressed\nsizes, CRC32 checksum, modification time, and several other\nflags. Many of these fields are redundant as they are stored\ntwice in both the CDH and the LFH. The central directory\nreduces file I/O operations by keeping information spatially\ncompact, while redundant metadata in the LFH can facil-\nitate data recovery. The End Of Central Directory Record\n(EOCDR) provides information to locate the central directory\nand an optional file comment field.\nThe common way of reading a ZIP file involves a series of\nsteps. The first step is to search for the EOCDR by its 4-byte\nsignature (50 4b 05 06), because the EOCDR is placed at\nthe end of the file with a variable size. The EOCDR provides\nthe position and size of the central directory and the number\nof CDHs. Then one can iterate through the CDHs and locate\nthe corresponding LFHs at the positions specified in each\nCDH. The metadata for each file is then available and the data\nthat follows the LFH can be decompressed.\nZIP files can be stored on a variety of storage medias, or\ntransmitted in a data stream without being stored. Seeking\nthe file and thus reading backward starting from the end of\nthe file is not always feasible, so there is also an alternative\n\"streaming\" way of reading a ZIP file right from the beginning,\nusing only the information in the LFHs to parse the ZIP\nfile, either ignoring the central directory and the EOCDR or\noptionally checking their consistency with the LFHs later.\nSince its first release in 1989, the ZIP file format has\nevolved a lot with many feature extensions. One of the most\nremarkable extensions is ZIP64 which utilize 64-bit integers\nto support file sizes larger than 4GiB. It consists of the ZIP64\nextended information extra field for representing large file\nsizes, and the ZIP64 End Of Central Directory Record (ZIP64\n\n432 34th USENIX Security Symposium\nUSENIX Association\n\nEOCDR) with a ZIP64 End Of Central Directory Locator\n(ZIP64 EOCDL) to support a large central directory with\nmore than 65535 entries. Besides the official extensions, there\nis also room for customized extensions through the extra fields\nin the CDH and LFH.\n\n2.2 Inconsistent ZIP Parsing Behaviors\nAlthough the ZIP file format was defined by PKWARE over\nthirty years ago, the specification document was casually writ-\nten, leaving many important details unspecified and open\nto different interpretations. In 2015, ISO/IEC 21320-1 [4]\nwas published to provide a formal standard for the ZIP file\nformat. However, the standard only imposes several restric-\ntions against the use of certain features, such as limiting the\nchoices of compression methods, restricting the charset of file-\nnames, and prohibiting the use of encryption, digital signature,\npatched data, and multi-volume spanning, without providing\nclarification for the previously unspecified details.\nThe ZIP file format is widely used for various purposes, and\nhas been implemented in numerous applications and software\nlibraries across a wide range of programming languages, each\nmay have its own interpretation of the ZIP specification. Not\nonly that the official specification is not clear enough, but the\nhuge number of independent implementations also renders it\nimpractical to name a de facto standard for ZIP. When it is\nhard to argue which one of two conflicting implementations\nis the correct one, an alternative solution is to reject inputs\nthat lead to inconsistent outputs. However, programmers tend\nto follow the Postel's Law, \"be conservative in what you do,\nbe liberal in what you accept from others\" [30], so parsers\nusually try their best to resolve malformed files instead of\nreporting errors. Consequently, it is common to see behavior\ndiscrepancies between ZIP parsers.\nThe first documented instance of ZIP parsing ambiguity\nvulnerability in the CVE list is CVE-2003-1154, where the\nattacker was able to bypass virus detection via malformed ZIP\nemail attachments [3]. Over the past twenty years, prior work\nmainly focused on discovering new instances of virus detec-\ntion bypassing. This kind of vulnerability occurs when the\nantivirus engine and the unarchive application used by the vic-\ntim user parse the ZIP file differently. The contents of the ZIP\nfile may appear innocent when parsed by the antivirus engine\nbut malicious when extracted by the unarchive application.\nA few vulnerabilities involve other scenarios, such as APK\nsignature verification [20] and Firefox add-on review [16].\n\n3 Overview\n3.1 Threat Model\nIn this paper, we consider an attacker who can craft a mali-\ncious ZIP file and deliver it to the victim. The attacker is not\nrestricted to conventional archiving tools. They can arbitrarily\n\nmanipulate the file at the byte level, even in ways that violate\nthe ZIP specification. The malicious ZIP file will then be pro-\ncessed by different parsers with varying interpretations of the\nfile contents, and these divergences can be exploited by the\nattacker to bypass security measures. We identified various\nreal-world exploitation scenarios, including secure email gate-\nway bypass, signature forgery, and content spoofing, which\nwill be detailed in Section 6.\n\n3.2 Motivating Example\nLocal File Header\ncompressed size: 13394B\nuncompressed size: 13394B\nFile Data\n4d 5a 90 00 03\nCentral Directory Header\ncompressed size: 1B\nuncompressed size: 1B\nextracted by unarchiver\nreading size from LFH\n4d 5a 90 00 03\n4d <EOF>\n↑\nextracted by antivirus\nreading size from CDH\n\nFigure 2: A motivating example to bypass secure email gate-\nway via a ambigious ZIP file\n\nIn Fig. 2 we present a real-world example of bypassing\nsecure email gateway using a malformed ZIP file. The ZIP\nfile contains a malware payload as a file stored in the archive.\nThe attacker manipulates the file size fields in the CDH corre-\nsponding to the malware, where the size of the file entry is set\nto one byte, so that some antivirus scanners that obtain the file\nsize from the CDH would fail to identify the malware, includ-\ning the ones used by mail.ru and inbox.lv. However, the size\nfields in the LFH are left untouched. Many ZIP unarchivers,\nincluding popular ones like WinRAR, 7-Zip, and Info-ZIP,\nuse the file size fields in the LFH and thus are able to extract\nthe malware. The victim user may trust the antivirus scan-\nning report and execute the extracted malware, and then the\nvictim's system will be infected by the malware.\nThis attack only manipulates the fields in the ZIP file and\nis independent of the specific content of the malware pay-\nload. No obfuscation, encryption, or transformation of the\nmalware is required. So this attack is broadly applicable to\nany malicious file payload.\n\n3.3 Research Questions\nThis paper answers the following research questions:\nRQ1: How do we systematically identify inconsistencies\nbetween ZIP parsers? Prior work [16, 20, 23] has identified\nindividual cases of ZIP parsing ambiguities. However, they\nrely on manual and ad hoc approaches for discovery. In this\npaper, we designed a mutation-based differential fuzzing tool\nZIPDIFF that analyzes the discrepancies between the outputs\nof multiple ZIP parsers to identify parsing inconsistencies and\n\nUSENIX Association\n34th USENIX Security Symposium 433\n\nto guide the fuzzing process. We combined grammar-aware\nmutations and byte-level mutations to generate the test sam-\nples. The ZIP file format has a complex structure and the field\nvalues often depend on each other. We carefully designed the\nmutation strategies to satisfy these requirements so that valid\nZIP files are generated with a high probability. According\nto the test results, we classified the parsing ambiguities into\nthree categories consisting of 14 distinct types along with\nroot-cause analysis.\nRQ2: What is the current prevalence of inconsistencies\namong real-world ZIP parsers? The ZIP file is not only one\nof the most popular archive formats, but also serves as the\ncontainer for many other file formats. It has a long history and\nis now used virtually everywhere. As a result, there are many\nZIP applications and libraries across different programming\nlanguages. In our study, we collected 50 different applications\nand libraries across 19 programming languages to discover\nZIP parsing ambiguities comprehensively and measure the\nprevalence of inconsistencies among real-world ZIP parsers.\nThe evaluation results show that almost all pairs of parsers\nare vulnerable to some parsing ambiguities.\nRQ3: How can these inconsistencies be exploited in\nreal-world products? We examined five scenarios where\na ZIP file is processed by multiple entities, revealing how\nparsing inconsistencies between them can be exploited. In\neach scenario, we identified vulnerabilities in widely used\nreal-world products and responsibly disclosed these issues\nto the vendors. Additionally, we proposed seven strategies to\nmitigate these vulnerabilities from various perspectives.\n\n4 Design and Implementation\n4.1 Workflow\nTo efficiently find discrepancies between ZIP parsers, we de-\nsigned and implemented ZIPDIFF, our mutation-based black-\nbox differential fuzzer for ZIP files. ZIPDIFF randomly gen-\nerates and mutates ZIP files, and then feeds them to multiple\nZIP parsers. The parsing outputs are used as criteria for select-\ning seeds for further mutations, feedback for the UCB-based\nmutation selection, and the indication of inconsistent parsing\nbehaviors. The overall workflow is illustrated in Fig. 3.\n\n4.2 Sample Generator & Mutator\nTo begin the fuzzing process, ZIPDIFF first generates some\nZIP file samples as the initial corpus. The sample generator\nrandomly selects the filenames and contents stored in the ZIP\narchive and ZIP parameters such as compression methods\nand ZIP feature set to build well-formed ZIP files. In fuzzing\niterations, ZIPDIFF randomly mutates the test samples. There\nare two types of mutation strategies:\nZIP-Level Mutations. Some test samples are stored as struc-\ntured ZIP files instead of raw bytes. The mutator is then able\n\nUpdate UCB weights\nZIP Mutation\n3. UCB-based\nmutation\nselection\n4. Feed mutated\ninput to parsers\nByte Mutation\nMutator\nZIP Parsers\n2. Select seed\nGenerator\nCorpus\n1. Generate\nwell-formed\ninitial seeds\nC\n5. calculate\noutput hash\n6. Collect\ninteresting\nseeds\nDifference\nAnalyzer\n\nFigure 3: Workflow of ZIPDIFF\n\nto locate and randomly mutate individual fields or a combina-\ntion of multiple fields. We designed 46 mutation strategies of\nthis type, covering every field of a legitimate ZIP file. These\nmutations are specially designed according to the semantic\ncharacteristics of different fields. For example, the compres-\nsion method is either selected within a set of valid options\nwith a high probability or randomly generated with a low\nprobability. Some mutation strategies repair the inter-field de-\npendencies such as the sizes and offsets so that more parsers\nare able to parse the mutated test samples successfully.\nByte-Level Mutations. To cover more edge cases, ZIPDIFF\nalso employs byte-level mutations, including byte insertion,\ndeletion, modification, duplication, splicing, and bit flipping.\nAfter byte-level mutations, the test sample will be stored as\nraw bytes without ZIP structures and ZIP-level mutations can-\nnot be applied afterwards. Note that some ZIP-level mutations\nact like byte-level mutations but target individual ZIP fields,\nsuch as flipping the flag bits in LFH and CDH.\nThe mutator may apply multiple mutations in a single iter-\nation to trigger ambiguities with a combination of mutations.\nOtherwise, the first mutation may be discarded if it does not\ntrigger ambiguities on its own, as mutated samples are added\nback to the corpus only when they are found to be interesting.\n\n4.3 Difference Analyzer\nZIPDIFF instructs each ZIP parser to read the sample ZIP file\nand extract it onto the file system. Each parser either success-\nfully produces an output directory or reports an error. The\ndifference analyzer computes a hash value of each successful\noutput directory for subsequent comparisons, as illustrated in\nAlgorithm 1 in Appendix A.\nIn preliminary experiments, we found that different parsers\noften process invalid characters in filenames inconsistently.\nHowever, inconsistencies in filenames are usually exploited\nonly for specific file paths, such as word/document.xml for\nDOCX files. These specific paths usually do not contain in-\nvalid characters, so the inconsistency is only exploitable if the\nfilenames are valid and controlled by the attacker. To filter out\nthe non-exploitable filename inconsistencies, all filenames\n\n434 34th USENIX Security Symposium\nUSENIX Association\n\ncontaining special or invalid characters are considered equal\nin the hashing process. Empty directories are also ignored in\nhash computation because they are not exploitable.\nAfter obtaining these hash values, the analyzer compares\neach pair of parsers to see which pairs are inconsistent. Two\nparsers are considered inconsistent on a test sample if they\nboth successfully extracted the sample file but the hash values\ndiffer. We do not regard a successful parser and a failing\nparser as inconsistent, because in practice inconsistencies are\nexploitable only when both parsers succeed in parsing the\nZIP file. ZIPDIFF classifies the test samples into interesting\nsamples and boring samples. A sample is interesting if it is not\ncovered by any other seed in the corpus. We say that sample A\nis covered by sample B if A does not introduce any additional\ninconsistent parser pair or successful parser compared to B.\nThe interesting sample detection algorithm is presented in\nAlgorithm 2.\n\n4.4 Mutation Strategy Selector\nWe implemented diverse mutation strategies targeting differ-\nent fields in the ZIP file format. Because certain field muta-\ntions have a higher likelihood of triggering parsing ambigui-\nties, the fuzzer should prioritize these high-impact strategies\nto enhance efficiency. However, accurately determining which\nstrategies are most effective requires sufficient sampling. Each\nmutation strategy needs to be tested multiple times to reliably\nassess its probability of causing parsing ambiguities.\nIn summary, we are now facing the classical problem of\nmaintaining balance between exploration and exploitation. To\nsolve this problem, we treat the mutation strategy selection\nprocess as a multi-armed bandit problem and utilizes the\nUpper Confidence Bounds (UCB) formula [7] to choose the\nmutation strategies during the fuzzing process. The weight of\neach mutation strategy is defined as follows:\n\nWi :=\nRi\nNi\n+\n2ln ∑K\ni=1 Ni\nNi\n(1)\n\nwhere Ni is the number of times the mutation is used, Ri is the\nreward of the mutation gained from interesting samples, and\nK is the total number of mutation strategies. When a sample is\nmutated by multiple strategies in a single iteration, the usage\ncount and reward are shared among them evenly.\nIn contrast to the original UCB algorithm, ZIPDIFF uses\nsoftmax (with a temperature parameter β) instead of argmax\nto select from the available options randomly and avoid using\nthe same mutation strategy repeatedly:\n\nchoice := weighted rand\ni∈ [1,K]\neβwi\n∑K\nj=1 eβwj\n(2)\n\nAs opposed to the standard multi-armed bandit problem,\nthe outcome of each mutation strategy changes over time, as\nthe corpus evolves during the fuzzing process. To appreciate\n\nthis property, ZIPDIFF decays the recorded usage count and\nreward over time by a rate of α in each iteration, so that recent\nevaluation results are weighted heavier than the old ones. The\noverall fuzzing process is illustrated in Algorithm 3.\n\n5 Evaluation and Findings\n5.1 Experiment Setup\nTo evaluate ZIPDIFF and measure the prevalence of ZIP pars-\ning inconsistencies, we collected 50 ZIP parsers across 19\nprogramming languages, including 4 applications and 46 pro-\ngramming libraries, as listed in Appendix B.\nThe applications are the most popular ones used by many\nend users, namely Info-ZIP, WinRAR, 7-Zip and its fork p7zip.\nFor libraries, we use the official utility or example programs\nif available. When a library only provide low-level APIs like\nreading the file entries, we prefer wrapper libraries with high-\nlevel operations such as extracting the whole archive. For\nexample, we use the miniunzip program provided by minizip\nitself, and we use the ZeroTurnaround ZIP library as a wrapper\nto test the ZIP classes provided by the Java standard library.\nWhen a library provides options to perform integrity checks\nfor ZIP files, we enable these options.\nSome libraries provide multiple sets of API to read ZIP\nfiles, usually a standard parsing method and a streaming one,\nas introduced in Section 2.1. In this case, we regard each set\nof API as a separate parser. We usually choose the latest stable\nversion of each parser at the time of evaluation, with a few\nexceptions. For example, we include both yauzl v2 and yauzl\nv3, because a wrapper library extract-zip based on yauzl\nv2 contributes more than ten million weekly downloads, 80%\nof the yauzl weekly download count.\nWe check the dependency graphs and search for ZIP format\nparsing logic in the code of every parser to ensure that the\nparsers are substantially different and do not depend on each\nother, except in the aforementioned situations where a sin-\ngle library provide different APIs, when we include multiple\nversions of the same library, or when we evaluate a library\nthrough its wrapper library.\nAs we include a variety of parsers across many program-\nming languages, to ensure maintainable code and reproducible\nevaluation, we configure each parser as a Docker image and\nrun them in isolated environments. In particular, we use wine\nto run WinRAR in Docker on Linux to unify the evaluation\nprocess. As Docker invocation is expensive, we run test cases\nin batches, dispatching test cases in each batch inside the\nDocker containers. All parsers run concurrently, while some\nslow parsers also process multiple test cases in parallel to pre-\nvent becoming the bottleneck and ensure maximal utilization\nof available computing resources.\nWe conducted our experiments on a Linux server equipped\nwith a 2GHz 112-core CPU and 944GB RAM.\n\nUSENIX Association\n34th USENIX Security Symposium 435\n\n5.2 Findings\nBased on the fuzzing results, we analyze the sample files in the\ncorpus and classify the identified ZIP parsing ambiguities as\n14 distinct types and group them into three major categories:\nredundant metadata, file path processing, and ZIP structure\npositioning, as detailed in the following subsections.\nIn addtion to mutation-based fuzzing, we also constructed\nsample files for each variant of the ambiguities and tested the\nparsers against these samples. We summarize the number of\ninconsistency types between each parser pair in Appendix C.\n1221 out of a total of 1225 pairs of parsers are affected by\nat least one type of ambiguity, demonstrating the prevalence of\ninconsistencies across ZIP parsers.\n\n5.2.1 Redundant Metadata\nMetadata for each file in a ZIP archive is typically stored\nin two locations, one in the local file header, and one in the\ncentral directory header. This design facilitates error recov-\nery and allows streaming data processing, but it also leads to\nambiguities when the metadata in different locations disagree.\nSome metadata are stored in extra locations besides LFH and\nCDH, such as the extra fields and the data descriptors, enlarg-\ning the room for ambiguities. In addition to identical metadata\nbeing stored in multiple locations, ambiguities can also occur\nwhen different metadata fields are capable of deriving the\nsame piece of information.\nCompression Method Confusion (A1). If the compres-\nsion method specified in the CDH and the one specified in\nLFH are different, the parser may implicitly choose one from\nthem. Although it is difficult or impractical to construct valid\ncompressed data that can be successfully decompressed by\nmultiple algorithms, ZIP allows storing a file without com-\npression, using the \"stored\" compression method. An attacker\ncan construct a ZIP file where the data is compressed but the\ncompression method in either CDH or LFH is modified to\n\"stored\". In this way, parsers that select the correct compres-\nsion method are able to extract the meaningful content, while\nthe others that select the \"stored\" compression method will\ndirectly use the compressed data as output.\nFile Size Confusion (A2). Two types of file sizes are stored\nin ZIP files: the compressed size and the uncompressed size.\nThe uncompressed size is redundant because it can be derived\nfrom the compressed data and the compression algorithm, but\nthe parser may use it to truncate or pad the decompressed\ndata. When the compression method is \"stored\", these two\nsizes should be identical, so the parser can choose either of\nthem. Besides CDH and LFH, both compressed and uncom-\npressed sizes can also be found in data descriptors and ZIP64\nextended information extra fields if the respective features\nare enabled. Moreover, a single CDH or LFH may contain\nmultiple ZIP64 extra fields. The size fields in the headers\nare set to 0xFFFFFFFF when using ZIP64 and are set to zero\nwhen using data descriptors, which might be mistakenly used\n\nas the actual size by a parser not supporting these features. In\nsummary, there are virtually an unlimited number of sources\nof file size information for the parser to choose from.\nThe integrity of files stored in a ZIP archive are protected\nby the CRC32 checksum. This integrity check is not enforced\nby many parsers, allowing attackers to manipulate the file data\nwithout worrying about the checksum. However, even if the\nintegrity check is enforced, as CRC32 is not a cryptographic\nhash function, it is easy to pad a byte sequence with extra bytes\nwhile maintaining the CRC32 checksum unchanged [40],\nmaking the File Size Confusion exploitation more powerful.\nFilename Confusion (A3). In addition to CDH and LFH,\nthe filenames can also be stored in the Info-ZIP Unicode path\nextra field (hereafter abbreviated as UP). UP was designed to\nstore a Unicode file path as an alternative to the ASCII file\npath. However, it does not enforce the presence of Unicode\ncharacters, and can be used to introduce a new source for the\nASCII filename. UP can override the original filename field,\nbut only a subset of parsers support this feature.\nUP has three subfields, version, name CRC32, and Unicode\nname. The version field is reserved for incompatible changes\nin the future. The name CRC32 field is the CRC32 check-\nsum of the original filename, used to verify that the Unicode\nname is updated correspondingly when the original filename\nis changed. When there are multiple UPs in the extra fields,\nthe parser has to select one of them. The selection strategy\nof the UP among multiple extra fields is usually implicitly\nimplemented rather than intentionally designed. It can be\nquite complex, as there are many factors that can influence\nthe selection process. We identified 6 edge cases: 1) The\nparser may select the first or the last UP in the extra fields.\nThe extra field could be in the CDH or the LFH; 2) A UP\nwith a version field not equal to 1 may be discarded. Some\nparsers discard only versions greater than 1, while others also\ndiscard version 0; 3) When the original filename does not\nmatch the name CRC32, the UP might be discarded; 4) In\nthe CRC32 check, some parsers use the filename field in the\nCDH/LFH as the \"original filename\", while some others use\nthe Unicode name from the previous UP; 5) When an invalid\nUP is discarded, the parser may either continue processing\nthe remaining extra fields or stop. If it stops, the filename may\nbe set to the last valid Unicode name or the original filename\nfrom the CDH/LFH; 6) There is a recently introduced lan-\nguage encoding flag in the CDH and LFH. This flag allows\nsetting Unicode filenames directly in the original filename\nfields, deprecating the use of UP. When the flag is set, some\nparsers stop processing UP, while others still recognize UP.\nFake Directory (A4). Files stored in a ZIP archive can be\neither a regular file or a directory. There are two information\nsources to determine whether a file is a directory. The first\nsource is whether the file path ends with a slash. Most parsers\nagree that a file path ending with a forward slash is a direc-\ntory, except a few that do not think any file with a non-zero\nsize is a directory. However, file paths that end with back-\n\n436 34th USENIX Security Symposium\nUSENIX Association\n\nslashes are not universally treated as directories. The second\nsource is the external file attributes field in the CDH. This\nfield is host-system dependent. There are different flag val-\nues representing a directory on MS-DOS and Unix. Parsers\nmay rely on either or both of the flags on different systems.\nThe version made by field indicates the host system. Some\nparsers determine the interpretation of external file attributes\nbased on the host system. Some parsers only recognize the\nUnix directory flag when the host system is Unix, but the Go\npackage archive/zip also recognizes the flag when the host\nsystem is OS X.\nFake Encryption (A5). When two parsers disagree about\nwhether a file in a ZIP archive is encrypted, and the file data\nis actually unencrypted, only the parser that identifies it as\nunencrypted will successfully extract the file contents. This\ndisagreement can arise from LFH-CDH confusion or from\ndifferences in parser support for file encryption. Furthermore,\nsince ZIP archives typically encrypt either all files or none\nof them, some parsers give up processing the entire archive\nupon encountering an encrypted file. Consequently, if only\nthe first file in an archive is encrypted, certain parsers will fail\nto extract any remaining files.\n\n5.2.2 File Path Processing\nA ZIP archive stores not only the contents of the files, but\nalso the paths to these files. Discrepancies related to file paths\nusually enable attackers to effectively switch which file is at a\nspecific path, thereby manipulate the contents of file formats\nthat use ZIP as a contanier.\nDuplicate Files (B1). When two or more files in a ZIP\narchive share the same path, and the parser is asked to retrieve\nthe file at this path, it has to either intentionally or implicitly\nmake a choice, where different parsers have divergent policies.\nDuplicate files also serve as a basis for other parsing ambigui-\nties in this category. For example, suppose that two parsers\nA and B both select the last one among duplicate files, then\nthe Duplicate Files ambiguity cannot be exploited on its own.\nHowever, with the help of some other parsing ambiguities, it\nwould be possible to make parser A treat two files as both\nhaving the same path x, while parser B thinks the first file has\npath x but the second file has path y. When asked to retrieve\nthe file with path x, parser A will see two files with path x and\nchoose the second one, but parser B will choose the first file\nas it is the only file with the given path.\nInvalid Characters (B2). Some characters are considered\ninvalid in file paths, such as ASCII control characters, invalid\nUnicode, and \"\" * : <>? |” on Windows. Parsers may remove\ninvalid characters or replace them with placeholders like “_”\nor \"?\". The valid character set and the processing mechanisms\nare different for each parser. Some parsers choose the text\nencoding based on the host system indicated by the version\nmade by field. When encountering the null character, the file\npath string could be terminated in the middle.\n\nPath Canonicalization (B3). There are multiple string rep-\nresentations of a single file path. For example, we can insert\nredundant slashes \"//\", replace forward slashes with back-\nslashes, or use single dot \".\" and double dots \"..\" to represent\nthe current directory and the parent directory. The attacker\ncan construct a ZIP archive (an ODT document) contain-\ning two files with paths content.xml and ./content.xml.\nWhen retrieving the file at a certain path, different parsers\nmay canonicalize the file paths inconsistently, so that some\nparsers think two files share the same path, while the other\nparsers think they are of different paths.\nCase Sensitivity (B4). Most parsers compare file paths\ncase-sensitively, but some parsers, especially those running\non Windows, handle file paths in a case-insensitive manner.\nAs a result, files with paths differing only in letter casing may\nbe regarded as duplicates.\n\n5.2.3 ZIP Structure Positioning\nBefore processing the file metadata and file paths, the first\nstep in parsing a ZIP file is to determine the positions of the\nZIP structures, i.e. to parse the EOCDR and the central direc-\ntory. If parsers read the headers and file data from different\npositions, the parsing result may be completely different.\nStreaming Parsing (C1). The standard mode for reading\nZIP files is to use the information in the EOCDR to locate\nthe central directory, and then locate individual LFHs through\nCDHs. Apart from that, LFHs can also be read sequentially\nfrom front to back in streaming mode, which introduces po-\ntential ambiguities. We describe several construction methods\nbelow. Although they utilize the same ambiguity, the diverse\nconstruction techniques make ambiguity detection difficult.\nIf detection is not comprehensive, it may be bypassed.\n1) No corresponding CDH for LFH. Parsers in standard\nmode usually only process LFHs referenced by CDHs, while\nparsers in streaming mode process all LFHs encountered\nduring reading. If a file in the archive only has an LFH but no\ncorresponding CDH, it is likely that only streaming parsing\ncan read this file.\n2) Truncating the LFH stream. In streaming mode, the\nparser reads consecutive LFHs until the end, where the end\nmarker may be any non-LFH data, CDH, or EOCDR. How-\never, in standard mode, LFHs can be placed anywhere, in-\ncluding after CDHs or even after the EOCDR. To avoid being\ndetected as an anomaly, either the LFH can be put inside the\ncomment field of a CDH or EOCDR, or the CDH or EOCDR\nthat terminates the LFH stream is not the real one used in the\nstandard mode.\n3) LFH desynchronization. In streaming mode, an LFH\nmust follow the previous entry's file data, while standard\nmode allows arbitrary LFH positioning. Thus, LFH positions\ncan differ: a standard mode LFH might be placed where\nstreaming mode expects file data. This may cause stream-\ning parsers to misinterpret the LFH as part of the file data,\n\nUSENIX Association\n34th USENIX Security Symposium 437\n\nthus missing the LFH. This can be implemented by either\nincluding only these asynchronous LFHs (creating \"holes\"\nof unused bytes in standard mode) or both streaming and\nasynchronous LFHs (causing entry overlap in standard mode).\nDetection requires checking for such holes and overlaps.\n4) Data descriptor position. ZIP's data descriptor feature,\ndesigned for streaming creation of ZIP files, places file sizes\nand checksum after the file data. In streaming parsing, without\nfile size information in the LFH, the data descriptor's position\n(i.e., the end of file data) is uncertain. Parsers usually search\nfor its signature to determine its position and may verify that\nits information matches the actual file data. A crafted file\nstructure can make streaming parsers end file data at the data\ndescriptor signature, while in standard mode, the signature is\npart of the file data. This can desynchronize LFH processing\nbetween the two modes. With a careful design, file sizes and\nother information can appear self-consistent in both modes,\nwithout causing holes or overlaps. To prevent this, streaming\nparsers should report an error when a data descriptor is used\nand the file size is unknown. Notably, compression methods\nlike Deflate inherently record the file size, so the position is\nknown even when using a data descriptor.\nEOCDR Selection (C2). The EOCDR is placed at the\nend of the ZIP file with a variable size to store the ZIP file\ncomment. It is possible to create a ZIP file containing mul-\ntiple EOCDR signatures, all of which can be regarded as\nvalid EOCDRs, since EOCDR signatures can be treated as a\npart of the comment field in an EOCDR. Most parsers scan\nthe ZIP file backward from the end and choose the first en-\ncountered EOCDR signature. As a consistency check, some\nparsers verify that the comment length field either matches\nor is not bigger than the actual length of the comment. When\nthe consistency check fails, the parser may either report an\nerror or skip the EOCDR with an incorrect comment length\nand continue searching for the next one. In the latter case, the\nparser may choose a different EOCDR from other parsers that\ndo not perform this consistency check.\nThe EOCDR selection policy used in libzip is unique and\nmore complex. For an EOCDR, libzip first checks if there\nare inconsistencies such as incorrect comment length or mis-\nmatched field values in a pair of CDH and LFH. When no\ninconsistency is found, it calculates a \"consistency\" score\nbased on the bounding byte range reached in the file, which\nis effective in detecting the outermost one among nested ZIP\narchives. Finally, the EOCDR with the highest \"consistency\"\nscore is selected. With this policy, an attacker can create some\ninconsistency in the ZIP structure corresponding to the last\nEOCDR to trick libzip into using another EOCDR.\nCDH Count Confusion (C3). The EOCDR provides infor-\nmation to parse the central directory, including the number\nof entries in the central directory. In particular, it provides\ntwo different forms of CDH count, one total CDH count, and\none CDH count in the current disk, as ZIP files can be split\ninto multiple disks. It also provides the size and the posi-\n\ntion of the central directory. All of these four fields can be\nused to determine the CDH count and may conflict with each\nother. We identfied 3 edge cases: 1) The total CDH count\nand current disk CDH count should match but may conflict\nwhen there is only a single disk; 2) The parser might read all\nCDHs inside the central directory, regardless of the values of\nthe CDH count fields; 3) The parser may respect the central\ndirectory size field, or use all bytes until the EOCDR as the\ncentral directory.\nIn addition, as the CDH count fields are 16-bit, they are\ninsufficient to represent large central directories with more\nthan 65535 entries. As a workaround, some ZIP implementa-\ntions store the actual CDH count modulo 65536 in EOCDR.\nConsequently, it is possible that two parsers both respect the\nsame CDH count field, but one of them thinks there is only a\nsingle CDH, while the other thinks there are 65537 CDHs.\nCD & LFH Offset Confusion (C4). The central directory\nis usually located by the offset field in the EOCDR. But some\nparsers assume that the EOCDR immediately follows the\ncentral directory with no gap between them, and thus use the\ncentral directory size to determine its position.\nWhen the offset and the size fields in the EOCDR mismatch,\nit does not necessarily indicate that there is a gap between the\ncentral directory and the EOCDR. It is also possible that the\nZIP file is padded with extra bytes at the beginning without\nadjusting the offset fields. For instance, this happens in self-\nextracting archives, where executable code is prepended to a\nZIP archive to extract itself. In order to support this use case,\nsome parsers not only assume that the EOCDR immediately\nfollows the central directory, but the offset fields in the CDHS\nthat point to the LFHs are also adjusted correspondingly. For\nexample, if the offset field in EOCDR has value x, but the size\nfield indicates that the actual offset to the central directory is\nx + 8, then for a CDH with LFH offset value y, the parser will\nuse y + 8 as the actual offset to locate the LFH.\nZIP64 EOCD Processing (C5). The ZIP64 extension was\ndeveloped to support ZIP files larger than 4GB and with more\nthan 65535 files. It mainly consists of the ZIP64 extended\ninformation extra field, the ZIP64 end of central directory\nrecord (ZIP64 EOCDR), and the ZIP64 end of central direc-\ntory locator (ZIP64 EOCDL). The ZIP64 EOCDL has a fixed\nsize and contains the offset to the ZIP64 EOCDR whose size\nis variable. This design enables determined processing of the\nZIP64 EOCDR without the need to search for its signature,\nbut it also introduces more discrepancies. We identified the\nfollowing ambiguities in ZIP64 EOCD processing: 1) The\nZIP64 EOCDL can be located by a fixed offset from the regu-\nlar EOCDR, or by searching for its signature; 2) The ZIP64\nEOCDR can be located based on the ZIP64 EOCDL, or by\nsearching for its signature; 3) It is unclear whether to use the\nZIP64 EOCDR or the regular EOCDR. A parser may use\nthe ZIP64 one whenever it is present, or only use the ZIP64\none when the fields in the regular one are set to 0xFFFFFFFF;\n4) If only a part of the fields in the regular EOCDR are set\n\n438 34th USENIX Security Symposium\nUSENIX Association\n\nto 0xFFFFFFFF, it is unclear whether to read all fields from\nthe ZIP64 EOCDR, or to partly read from the regular one\nand mix fields from both ZIP64 and the regular EOCDR; 5)\nZIP64 EOCDR provides an extra chance to suffer from the\nsame issues as the regular EOCDR, including CDH Count\nConfusion (C3) and CD & LFH Offset Confusion (C4).\n\n5.3 Ablation Study\nTo evaluate our design decisions, we conducted an ablation\nstudy by comparing the performance of the following setups:\n• Full Setup: As described in Section 4.\n• Argmax-Based UCB: Use the original argmax-based\nUCB algorithm instead of our version that uses softmax\nfor more randomness in mutation (Section 4.4).\n• Byte Mutation Only: Use only the general byte-level\nmutations but not the ZIP-level mutations tailored for\nindividual fields in the ZIP file format (Section 4.2).\n\nWe ran five 24-hour fuzzing sessions for each setup and\nplot the results in Fig. 4. The median numbers of discovered\ninconsistent parser pairs are 1197, 1183, and 1055 for the\nthree setups, where the full setup outperforms the others. The\nsoftmax-based UCB algorithm allows exploring different mu-\ntation strategies in the same batch. The ZIP-level mutations\ncan generate more valid samples and trigger more inconsis-\ntencies by focusing on mutating individual fields.\n\nInconsistent Pairs (Median)\n1200\n1150\n1100\n1050\nFull Setup\nArgmax-Based UCB\nByte Mutation Only\n1000\n1000\n0\n4\n8\n12\nTime (hours)\n16\n20\n24\n\nFigure 4: Median number of inconsistent parser pairs over\ntime for each experiment setup.\n\n6 Real-world Exploitations\nIn this subsection, we present five real-world scenarios where\ninconsistencies between ZIP parsers are weaponized. These\nscenarios target inconsistencies between different pairs of\nparsers in various applications, demonstrating the broad im-\npact of ZIP parsing ambiguities.\n\nTable 1: Antivirus bypass results for email products. The\nFilename Confusion (A3) type and the File Path Processing\n(B) category involve the filenames rather than the contents,\nso they have impacts on container formats but not antivirus\nbypass and are therefore excluded here.\n● Vulnerable Not Vulnerable\n\n| Product | Redundant Metadata (A) | ZIP Structure Positioning (C) |\n|---|---|---|\n| | 1 | 2 | 4 | 5 | 1 | 2 | 3 | 4 | 5 |\n| Coremail | ● | ● | ● | ● | ● | ● | ● | ● | ● |\n| Gmail | ◦ | ● | ◦ | ◦ | ● | ● | ● | ● | ● |\n| iCloud | ● | ● | ● | ● | ● | ● | ● | ● | ● |\n| inbox.lv | ● | ● | ◦ | ● | ● | ● | ● | ● | ● |\n| mail.com | ● | ● | ◦ | ● | ● | ● | ● | ● | ● |\n| mail.ru | ● | ● | ● | ● | ● | ● | ● | ● | ● |\n| Naver | ◦ | ● | ● | ● | ● | ● | ● | ● | ● |\n| Outlook | ● | ● | ◦ | ● | ● | ● | ● | ● | ● |\n| Proton | ● | ● | ◦ | ● | ● | ● | ● | ● | ● |\n| Zoho | ● | ● | ● | ● | ● | ● | ● | ● | ● |\n\n6.1 Secure Email Gateway Bypass\nThis scenario targets parsing inconsistencies between an-\ntivirus scanners and ZIP unarchivers. An attacker can craft a\nmalicious ZIP file containing malware that can be extracted\nby a ZIP unarchiver but cannot be detected by the antivirus\nscanner. For example, the antivirus scanner might read trun-\ncated malware, treat compressed malware as uncompressed,\nregard the malware as a directory instead of a regular file, or\nassume that the malware is encrypted and give up processing.\nFor host-based antivirus software, this kind of bypass usu-\nally has limited impact since the malware is likely to be de-\ntected during on-access scanning when the user extracts the\nZIP archive. However, it is more critical in remote environ-\nments such as secure email gateways, where host-based de-\nfense might be absent in the end user's system. For instance,\nGmail will scan attachments in the emails and display a note\n\"Scanned by Gmail\" besides the attachments. When a user\nreceives an email with an attachment passing the secure email\ngateway, they may trust its content based on the scanning\nresult and open it through a ZIP unarchiver that is able to\nextract the malware, and then the system will be infected.\nWe tested various ZIP parsing ambiguity constructions on\npopular email products that provide virus scanning services\nand allow us to register free testing accounts. We first send\nan email to our testing account with a safe ZIP attachment to\nverify that it can be delivered to the inbox and another email\nwith a well-formed ZIP file containing malware to verify that\nit is rejected. Then we send emails with malformed ZIP files\nwith malware for antivirus bypass testing. All tested email\nproducts are vulnerable to some construction methods, as\nlisted in Table 1.\n\nUSENIX Association\n34th USENIX Security Symposium 439\n\n6.2 Office Document Content Spoofing\nThis scenario targets parsing inconsistencies between differ-\nent office applications, including office suites like Microsoft\nOffice and LibreOffice, as well as Web applications such as\nplagiarism checkers and AI assistant services (e.g. ChatGPT,\nClaude, DeepSeek, etc.) that process office documents.\nAn office document is a ZIP file containing some XML\nfiles. The document content is stored in the file with a cer-\ntain file path, such as word/document.xml in DOCX files\nand content.xml in ODT files. An attacker can construct\nan office document that is parsed inconsistently by differ-\nent applications, so that these applications will see different\ndocument content.\nThe security implications of content spoofing depend on\nthe specific use cases. A representative case is plagiarism\nchecker bypassing, where an unethical student can construct\na document such that plagiarized content is displayed in the\noffice suite but hidden from the plagiarism checker. The super-\nvisor reads the document in the local office suite application\nand sends the document to a remote service to detect plagia-\nrism. The supervisor will read the plagiarized content but may\ntrust its originality based on the plagiarism checker report.\nCase Study 1. The plagiarism checker provided by China\nNational Knowledge Infrastructure locates the XML file case-\ninsensitively and picks the last one among duplicate files.\nIn contrast, Libreoffice ignores WORD/DOCUMENT. XML in up-\npercase, vulnerable to Case Sensitivity (B4). WPS Office on\nWindows locates the file case-insensitively but selects the first\none among duplicate files, vulnerable to Duplicate Files (B1).\nCase Study 2. A dishonest student can construct a docu-\nment with the structure shown in Fig. 5. The two columns of\nthe table represents two possible parsing results, where each\nrow in both columns represents the same bytes in the ZIP\nfile. It exploits ZIP64 EOCD Processing (C5), where ZIP64\nEOCDR and EOCDL are present in the ZIP file, but the fields\nin the regular EOCDR are not set to 0xffffffff as required\nin the specification. In this case, Microsoft Office, LibreOffice,\nand WPS Office will ignore the ZIP64 EOCDR and use the\ncentral directory corresponding to the regular EOCDR, thus\nreading the word/document.xml with plagiarism, as the right\ncolumn in Fig. 5, where the extra word/document.xml and\nZIP64 EOCD are treated as a CDH comment field by set-\nting the comment length field in the last CDH. However,\nthe PapersOwl plagiarism checker will recognize the ZIP64\nEOCDR and read the word/document.xml without plagia-\nrism, as the left column in Fig. 5, so it will report no plagia-\nrism in the document. In addition, the Grammarly plagiarism\nchecker works in the Streaming Parsing (C1) mode. It also\nparses the document as the left column, but it reads the LFHS\none by one instead of relying on the ZIP64 or regular EOCDR.\n\nZIP64/Streaming Regular EOCDR\n(plagiarism checker) (document display)\nother files ([Content_Types].xml, etc.)\nLFH for foo.xml\ndata for foo.xml\nword/document.xml\nwithout plagiarism\ncentral directory\nZIP64 EOCDR\nZIP64 EOCDL\nword/document.xml\nwith plagiarism\ncentral directory\nCDH comment\nEOCDR (fields are not set to Oxffffffff)\n\nFigure 5: Plagiarism checker bypass example\n\nLegitimately Signed Document\nMalicious Document\nSignature & Other Files\nVerify\nSignature & Other Files\nLFH filename: aaaaaaaaaaaaaaaaa\nCDH filename: word/document.xml\nData: Legitimate document\nLFH filename: word/document.xml\nCDH filename: aaaaaaaaaaaaaaaaa\nData: Malicious document\nDisplay\nLFH filename: word/document.xml\nCDH filename: word/document.xml\nData: Legitimate document\n\nFigure 6: LibreOffice document signature forgery example\n\n6.3 LibreOffice Document Signature Forgery\nThis scenario targets parsing inconsistency between the signa-\nture verifier and the document viewer of LibreOffice. Suppose\nthat the attacker has obtained a legitimately signed document.\nWith the legitimate signature and the corresponding document\ncontent, the attacker can construct a malicious document. Due\nto parsing inconsistency, the signature verifier sees the origi-\nnal legitimate content and reports that the signature is valid.\nHowever, the document viewer displays the manipulated con-\ntent, leading to signature forgery.\nDifferent components in a single application usually use\nthe same parser and are thus not vulnerable to parsing dis-\ncrepancies. In this specific case, LibreOffice indeed uses the\nsame parser for signature verification and document display.\nHowever, the parser has a normal mode and a recovery mode,\nwhere the normal mode detects inconsistencies in the ZIP file\nbut the recovery mode ignores errors and works in the stream-\ning parsing mode. When the parser in the normal mode finds\na document to be corrupted, it will use the recovery mode to\ndisplay the document, but the signature validation still uses\nthe normal mode and the valid status remains unchanged.\nCase Study. Based on a signed document, the attacker\nmodifies the original word/document.xml entry to change\nits filename field in the LFH and adds a new entry with file-\n\n440 34th USENIX Security Symposium\nUSENIX Association\n\nname field word/document.xml in LFH to exploit the File-\nname Confusion (A3) ambiguity, as illustrated in Fig. 6. The\nsignature verifier will validate the signature against the file\nwith word/document.xml as CDH filename, but the docu-\nment displayer will show the file with word/document.xml\nas LFH filename after entering the recovery mode.\n\n6.4 Spring Boot Nested JAR Signature Forgery\nThis scenario targets parsing inconsistency between two JAR\nparsers used by the NestedJarFile class in Spring Boot\nLoader. A custom ZIP parser ZipContent is implemented\nto read the content of a JAR file, which operates in the stan-\ndard ZIP parsing mode. However, the Jar InputStream class\nprovided by Java is utilized to verify its signature, with the\nStreaming Parsing (C1) mode. Therefore, with a legitimately\nsigned nested JAR file, the attacker can forge a new one with\narbitrary contents and pass the signature verification.\n\n6.5 VS Code Extension ID Impersonation\nThis scenario targets parsing inconsistency between the VS\nCode extension Marketplace server and the VS Code client.\nVS Code extension packages are ZIP files. The Marketplace\nensures that authors can publish extensions only within their\nown namespaces. The publisher and extension ID are recorded\nin the extension.vsixmanifest file. The server and the\nclient are vulnerable to Filename Confusion (A3), allowing the\nattacker to construct an extension package such that the server\nand the client read different extension.vsixmanifest files\nand thus different publishers, and then the attacker will be\nable to circumvent the namespace isolation rule.\nCase Study. Suppose that the attacker owns the namespace\nattacker and the target extension is bob.foo. The attacker\ncan publish a malicious extension exploiting the Unicode\npath extra field such that the Marketplace server recognizes\nits ID as attacker.bar but the VS Code client reads its ID as\nbob.foo, as demonstrated in Fig. 7. Consequently, if a victim\nuser installs the malicious extension, it will impersonate the\ntarget extension and replace the originally installed one.\n\nMalicious Extension\nFile Name: extension.vsixmanifest\nUnicode Path Extra Field: foo.xml\nData: ... Id=bar Publisher=attacker ...\nFile Name: foo.xml\nUP Extra Field: extension.vsixmanifest\nData: ... Id=foo Publisher=bob ...\nMarketplace:\nThe attacker has\npermission to publish\nVS Code Client:\nThis extension\noverwrites bob.foo\n\nFigure 7: VS Code extension ID impersonation example\n\n7 Discussion\n7.1 Responsible Disclosure\nWe have reported our findings to the affected vendors and\ncoordinated in addressing these issues. We received many\nacknowledgments and bounty awards, as summarized below.\n\n7.1.1 Email Services\n• Gmail: acknowledged our report, rated the vulnerability\nas medium severity with a bug bounty reward of $1337,\nand deployed defense against the reported issues.\n• Coremail: acknowledged our report, rated the vulnera-\nbility as medium severity with a bug bounty reward of\nabout $400, and arranged to fix the reported issues.\n• Zoho: acknowledged our report, rated the vulnerability\nas medium severity with a bug bounty reward of $200\nand deployed defense against the reported issues.\n• Outlook: acknowledged our report and rated the vulner-\nability as low severity with an entry in the MSRC Online\nServices Acknowledgements. They also improved their\nantivirus scanning logic according to our report.\n• Proton Mail, Naver, mail.com, and mail.ru: our reports\nwere acknowledged but not eligible for bounty rewards.\n• iCloud: said they were still investigating our report.\n• inbox.lv: has not responded to our report yet.\n\n7.1.2 Office Applications\n• LibreOffice: promptly acknowledged our reports on\nboth content spoofing and signature forgery. They car-\nried out an in-depth conversation with us and inspired us\nto develop some novel bypass techniques against their\nproposed patches. They fixed these issues and assigned\nCVE-2024-7788 for the signature forgery vulnerability.\n• cnki.net: acknowledged our report on plagiarism scan-\nning bypass and planned to fix the issue.\n\n7.1.3 ZIP Parsers\n• Go archive/zip: acknowledged our report, assigned\nCVE-2024-24789, and changed their implementation\nto reject truncated EOCDR comments.\n• libzip: acknowledged our report and changed their\nunique implementation of EOCDR selection to align\nwith other parsers in the lax mode and report an error\nin the strict mode. They have also implemented stricter\nconsistency checks according to our suggestions.\n\nUSENIX Association\n34th USENIX Security Symposium 441\n\n7.1.4 Others\n• Spring Boot: acknowledged our report, assigned CVE-\n2024-38807, and fixed the vulnerability.\n• Open VSX: acknowledged our report and implemented\na check for malicious extension packages.\n\n7.2 Mitigation\nWe propose seven mitigation strategies with different con-\ncerns and trade-offs. Developers can choose the most appro-\npriate mitigation according to the specific situation.\nUse the same parser. If all parsers used in a workflow\nare controlled by the same party, then the best solution is to\nuse the same parser in all places. However, the parsers are\nusually controlled by multiple parties, where no single party\ncan control the parsers used by others, so this simple solution\nhas limited applications.\nOn-access scanning. Antivirus software typically uses on-\naccess scanning to compensate for the shortcomings of di-\nrectly scanning archive files. This is not only a solution for\nantivirus, but the same concept also applies to other scenar-\nios, where a component can use the parsing result of another\ncomponent instead of parsing the ZIP file again. It can be\nregarded as a special way to enforce using the same parser.\nFor example, a plagiarism checker may work directly inside\nan office suite, using the parsing result from the office suite.\nNormalize the ZIP file. To exploit ZIP parsing ambiguities,\nthe attacker usually needs to carefully manipulate the fields\nof a ZIP file, which cannot be achieved by a regular ZIP\narchiver. Most ambiguities will disappear if the ZIP file is\nfirst extracted and then repacked. Therefore, if we care about\nonly the contents but not the integrity of the whole ZIP file,\nwe can normalize the ZIP file by extracting and repacking it\nbefore processing.\nIdentify ambiguous patterns in ZIP files. Malformed ZIP\nfiles can be identified by special patterns, such as unused\nbytes and conflicting field values in CDH and LFH. For in-\nstance, libzip provides a CHECKCONS flag with intensive con-\nsistency checks, and LibreOffice warns users of malformed\ndocument files. A service may reject or report all malformed\nZIP files without affecting legitimate users, as malformed files\nare usually intentionally crafted. However, the identification\nof ambiguous patterns relies on existing knowledge, and pre-\nviously unknown ambiguities are hard to detect. In addition,\nmalformed ZIP files also have legitimate use cases, such as\nself-extracting files with prepended executable code and APK\nwith signature data before the central directory.\nIncorporate different parsing logics. Instead of relying on\nsome pre-defined patterns, a service can identify ambiguous\nZIP files by incorporating multiple parsers to see if they pro-\nduce consistent outputs. This can potentially detect previously\nunknown ambiguities. However, a large number of parsers are\nneeded to cover all ambiguities, and it may consume a large\n\namount of system resources to extract an archive multiple\ntimes. An alternative approach is to combine multiple parsing\nlogics or try all possible choices in a single parser. For in-\nstance, Gmail identifies all CDHs and the corresponding files,\neven if they are overlapped or outside of the central directory.\nFix unique parsing behaviors. Parsing ambiguities can also\nbe mitigated by making parsers behave consistently. Since the\nZIP specification is vague and lacks many important details,\nthere is no de facto standard, and it is usually infeasible to\ndetermine which parsers are correct when the implementa-\ntions are inconsistent. It is challenging to collaboratively fix\ninconsistencies without the presence of a standard, but we\ncan address the outlier behaviors where a few parsers behave\ndifferently from the majority of other parsers.\nBetter file format design. If we were able to redesign the\nZIP file format or to design a new archive format, we could\nlearn from the history and design a better file format:\n• Each part of a format must be unambiguously located. It\nis a bad idea to rely on fragile signature searching.\n• Conflicting data resolution should be clearly defined,\nideally by avoiding redundant data in the first place.\n• Leave room for backward-compatible feature extensions.\nMake it clear whether an extension is enabled or not.\n• Fields that are allowed to be silently ignored should not\ncontain security-sensitive data. For example, the extra\nfields in ZIP should not contain filenames and sizes.\n\n7.3 Limitation\nWe chose blackbox fuzzing so that we can support more\nparsers and programming languages to uncover more ambigu-\nities. As a blackbox fuzzer, ZIPDIFF only receives the parsing\noutputs as feedback and does not utilize greybox feedback\nlike code coverage. It might generate more sophisticated test\nsamples with cross-language coverage-guided fuzzing.\nZIPDIFF instructs the parsers to extract ZIP archives onto\nthe file system in order to unify the testing process and pro-\nvide easier parser integration. However, the output on the file\nsystem might not match the internal parsing result exactly.\nFor example, duplicate files may be overwritten either in the\ninternal state or when writing to the file on the disk. It may\nobtain more accurate results if the internal states are recorded.\nAlthough we only identified vulnerabilities in five scenar-\nios, the ZIP file format is also used in other security-sensitive\nscenarios. Further research may extend our results to broader\nfields. For instance, the 3MF data format used in 3D printing\nis based on ZIP and vulnerable to UI spoofing attacks [33].\nWhile we focus on plagiarism checkers for the office docu-\nment content spoofing scenario, it is also interesting to see\nwhether this can be used for indirect prompt injection attacks\nagainst large language models.\nBesides ZIP, other archive formats like TAR also suffer\nfrom parsing ambiguities [19]. However, ZIP is structurally\n\n442 34th USENIX Security Symposium\nUSENIX Association\n\nmore complex, consisting of LFHs, CDHs, and EOCDR. In\ncontrast, TAR uses a simpler linear header structure, supports\nfewer extensions, and separates archiving from compression.\nWe focus on ZIP in this paper because its complexity makes\nit more prone to semantic gaps. ZIPDIFF could be extended\nto handle other archive formats by replacing the ZIP-level\nmutations with other format-specific mutation strategies. We\nleave this extension as future work.\n\n8 Related Work\n8.1 Semantic Gaps and Differential Testing\nThere is a rich literature on semantic gaps in various as-\npects of network security, including TLS [8, 10,13,21,37,41],\nRPKI [24], QUIC [31], HTTP [11, 18, 35, 44, 50], CSP [46],\nURL [5, 32, 36, 39, 45, 47], HTML [22], JSON [25], and\nEmail [12, 43, 49]. These works use various methods to ana-\nlyze semantic gaps, ranging from manual, ad-hoc testing to\nblackbox and greybox differential fuzzing.\nPetsios et al. developed a domain-independent differential\ntesting framework called NEZHA [28] and demonstrated its\neffectiveness by uncovering parsing discrepancies in ELF, XZ,\nPDF, and TLS. Our fuzzer ZIPDIFF determines interesting\nseeds by two metrics ok and incons, as illustrated in Algo-\nrithm 2. The ok metric is essentially the output 8-diversity\nproposed by Petsios et al., if we only care about the success\nstatus but not the output contents. Since ZIP parsers produce\ncomplex file trees as outputs, it is impractical to use the entire\noutput contents as the output diversity. To utilize the output\ncontents in fuzzing guidance, ZIPDIFF uses pairwise equality\nas the incons metric.\nZheng et al. [50] incorporated the UCT-Rand algorithm to\nselect grammar nodes in their generation-based fuzzer RE-\nQSMINER. In contrast, our mutation-based fuzzer ZIPDIFF\nutilizes UCB to guide mutation strategy selection. We use the\nsoftmax function as a balance between the original argmax-\nbased UCB and UCT-Rand.\n\n8.2 ZIP Parsing Ambiguities\nAs early as 2008, Alvarez and Zoller presented a talk [34,51]\non antivirus evasion based on parsing discrepancies of various\narchive formats, including ZIP, RAR, and CAB. They revis-\nited these issues in 2020 [52] and found that many antivirus\nengines are still vulnerable. Vuksan et al. gave a similar talk\nin 2010 [42], revealing more bypass techniques. Coldwind\nalso presented talks [14, 15] that summarized attack surfaces\nof the ZIP file format including parsing ambiguities.\nJana and Shmatikov [19] proposed two types of an-\ntivirus bypass attacks based on file parsing ambiguities: the\nChameleon attack exploits conflicting file type detection and\nthe Werewolf attack exploits inconsistent parsing logic of the\nsame file type. Their work suggested that many file types are\n\nvulnerable to both attacks, including archive formats like ZIP\nand other formats like ELF.\nPanakkal [26] summarized several vulnerabilities on mal-\nformed APK files, and constructed a ZIP file that can be rec-\nognized as multiple container formats by mixing files related\nto different formats.\nTwo more vulnerabilities are also caused by ZIP pars-\ning ambiguities. One [16] exploits inconsistencies between\nparsers used in the Mozilla Firefox add-on review pipeline to\nsubmit malicious add-on that appears benign at review time.\nThe other [23] exploits a custom signature mechanism utiliz-\ning the file comment field in the EOCDR to bypass signature\nverification in firmware updates.\nIn summary, there is a lack of systemantic research on ZIP\nparsing ambiguities, with most previous studies focusing on\nindividual vulnerabilities. Our work provided the first system-\natic synthesis of existing knowledge, developed a differential\nfuzzer, uncovered additional ambiguity classes, extended con-\nstruction techniques, delivered an up-to-date evaluation of\n50 parsers across 19 programming languages, and identified\nvulnerabilities in novel scenarios.\nTo the best of our knowledge, among the 14 ambiguity\ntypes, ten of them are discovered or extended by us with\nnovel variants and techniques to cause more inconsistencies\nand bypass some checks. Details are listed in Table 2.\n\nTable 2: Novelty of the ZIP ambiguity types\n◦ New ambiguity discovered by us — Known ambiguity\n\n| Type | Novel | New type, variant, or technique |\n|---|---|---|\n| A1 | ◦ | |\n| A2 | ◦ | Multiple ZIP64 & Fixing CRC32 |\n| A3 | ◦ | Unicode path extra field techniques |\n| A4 | ◦ | Filename ending with backslash & Host system support in file attributes |\n| A5 | ◦ | CDH vs LFH inconsistency for the \"encrypted\" general purpose flag |\n| B1 | — | |\n| B2 | ◦ | Special characters besides null byte & Affected by the host system field |\n| B3 | — | The entire type is novel |\n| B4 | — | |\n| C1 | ◦ | Multiple construction techniques to bypass inconsistent ZIP file checking |\n| C2 | ◦ | Coldwind [15] mistakenly stated that libzip selected the first EOCDR. We identified the real mechanism used by libzip and some other parsers. |\n| C3 | ◦ | Total vs current disk CDH count |\n| C4 | — | |\n| C5 | ◦ | The entire type is novel |\n\nUSENIX Association\n34th USENIX Security Symposium 443\n\n8.3 Other ZIP Attacks\nBesides parsing ambiguities, the ZIP file format also suffers\nfrom other attacks, such as ZIP bomb and ZIP Slip.\nThe data amplification attack, known as ZIP bomb, exhausts\nremote servers' resources by highly-compressed ZIP files.\nPellegrino and Balzarotti [27] investigated the use of data\ncompression in network services and analyzed relevant pitfalls\nand vulnerabilities. Canet et al. [9] focused on decompression\nquines, archives that decompress to themselves, and their\nimpact on antivirus engines. Fifield [17] constructed a ZIP\nbomb that reaches a compression ratio of over 28 million by\noverlapping entries in a ZIP file, without the need of nested\narchives or uncommon compression algorithms. Their work\nalso highlighted the compatibility issues among ZIP parsers,\nalthough from a perspective of finding universally working\nZIP bombs rather than exploiting these inconsistencies.\nZIP unarchivers are also vulnerable to path traversal at-\ntacks, where files with malicious paths (../) are extracted\noutside of the target directory. The earliest instances of such\nvulnerabilities on the CVE list are CVE-2001-1268 [1] and\nCVE-2001-1269 [2]. Years later, the Synk security team iden-\ntified many ZIP applications were vulnerable and branded the\nvulnerability as ZIP Slip [38].\nMitigation of path traversal can lead to inconsistencies\nin Path Canonicalization (B3). For example, some parsers\nremove ../ in the file paths, while others resolve them and\ncheck whether the final result is inside the target directory.\nA file path foo/../bar is transformed to foo/bar in the\nformer, but bar in the latter.\n\n9 Conclusion\nThis paper presented the ZIPDIFF differential fuzzing tool and\nevaluated it on 50 ZIP parsers across 19 languages. The result\nrevealed that almost all pairs of ZIP parsers are inconsistent.\nWe summarized ZIP parsing ambiguities as 14 distinct types\nin three categories with different root-causes. These ambigui-\nties can be exploited in various real-world scenarios as ZIP\nis used in numerous applications. The vulnerabilities can be\nmitigated by incorporating suitable defense strategies.\nBy examining ZIP parsing ambiguities as a specific in-\nstance of the broader problem on semantic gaps, our work\nhighlights the critical need for rigorously defined file formats\nand consistent parser implementations. We hope this study\nnot only inspires the community to identify and reduce dis-\ncrepancies between ZIP parsers and to address the relevant\nvulnerabilities, but also raises general awareness of the secu-\nrity implications of semantic gaps.\n\nAcknowledgments\nWe sincerely thank all anonymous reviewers for their insight-\nful and constructive feedback that greatly helped improve the\n\npaper and the artifacts. This work is supported by the National\nNatural Science Foundation of China (grant #62272265).\n\nEthics Considerations\nWe have responsibly disclosed the identified vulnerabilities\nto the affected vendors, as listed in Section 7.1.\nIn the email product tests, we sent the emails with malicious\nattachments from our own server to our own email product\naccounts. We did not send malicious emails to any other user\nor from these email products. We throttled the email-sending\nfrequency to avoid excessive pressure on the products.\nIn the plagiarism checker tests, we uploaded the malicious\ntesting documents to the plagiarism detection services using\nour own account when an account was required. We did not\nsend these malicious documents to other people.\nIn the VS Code extension tests, we published the testing VS\nCode extension on the marketplace with an explicit warning\nin the extension description that it is used for testing purposes\nonly. It also does not contain any destructive functions. Only\na popup message is used to indicate that the modified version\nof the extension is running.\n\nOpen Science\nWe share the artifacts on Zenodo [48] and GitHub² for the\nfollowing components: the ZIPDIFF differential fuzzer (Sec-\ntion 4) along with ablation study options (Section 5.3), the\nDocker images of the tested ZIP parsers (Table 3), construc-\ntion of ambiguous ZIP file samples (Section 5.2), and utility\nscripts to reproduce the results.\n\nReferences\n[1] CVE-2001-1268, 2001. https://nvd.nist.gov/vul\nn/detail/CVE-2001-1268.\n\n[2] CVE-2001-1269, 2001. https://nvd.nist.gov/vul\nn/detail/CVE-2001-1269.\n\n[3] CVE-2003-1154, 2003. https://nvd.nist.gov/vul\nn/detail/CVE-2003-1154.\n\n[4] ISO/IEC 21320-1:2015(E) Information Technology —\nDocument Container File – Part 1: Core, 2015.\n\n[5] Dashmeet Kaur Ajmani, Igibek Koishybayev, and\nAlexandros Kapravelos. yoU aRe a Liar://A Unified\nFramework for Cross-Testing URL Parsers. In 2022\nIEEE Security and Privacy Workshops (SPW), pages 51-\n58, San Francisco, CA, USA, May 2022. IEEE. https:\n//doi.org/10.1109/SPW54247.2022.9833883.\n\n²https://github.com/ouuan/ZipDiff\n\n444 34th USENIX Security Symposium\nUSENIX Association\n\n[6] Abhishek Arya, Oliver Chang, Jonathan Metzman,\nKostya Serebryany, and Dongge Liu. OSS-Fuzz. https:\n//github.com/google/oss-fuzz.\n\n[7] Peter Auer, Nicol O Cesa-Bianchi, and Paul Fischer.\nFinite-time Analysis of the Multiarmed Bandit Problem.\nMachine Learning, 47:235–256, May 2002. https://\ndoi.org/10.1023/A:1013689704352.\n\n[8] Chad Brubaker, Suman Jana, Baishakhi Ray, Sarfraz\nKhurshid, and Vitaly Shmatikov. Using Frankencerts for\nAutomated Adversarial Testing of Certificate Validation\nin SSL/TLS Implementations. In 2014 IEEE Symposium\non Security and Privacy, pages 114-129, San Jose, CA,\nMay 2014. IEEE. https://doi.org/10.1109/SP.2\n014.15.\n\n[9] Margaux Canet, Amrit Kumar, Cédric Lauradoux, Mary-\nAndréa Rakotomanga, and Reihaneh Safavi-Naini. De-\ncompression Quines and Anti-Viruses. In Proceedings\nof the Seventh ACM on Conference on Data and Appli-\ncation Security and Privacy, pages 23-34, Scottsdale\nArizona USA, March 2017. ACM. https://doi.org/\n10.1145/3029806.3029818.\n\n[10] Chu Chen, Pinghong Ren, Zhenhua Duan, Cong Tian,\nXu Lu, and Bin Yu. SBDT: Search-Based Differential\nTesting of Certificate Parsers in SSL/TLS Implemen-\ntations. In Proceedings of the 32nd ACM SIGSOFT\nInternational Symposium on Software Testing and Anal-\nysis, pages 967–979, Seattle WA USA, July 2023. ACM.\nhttps://doi.org/10.1145/3597926.3598110.\n\n[11] Jianjun Chen, Jian Jiang, Haixin Duan, Nicholas Weaver,\nTao Wan, and Vern Paxson. Host of Troubles: Multi-\nple Host Ambiguities in HTTP Implementations. In\nProceedings of the 2016 ACM SIGSAC Conference on\nComputer and Communications Security, pages 1516-\n1527, Vienna Austria, October 2016. ACM. https:\n//doi.org/10.1145/2976749.2978394.\n\n[12] Jianjun Chen, Vern Paxson, and Jian Jiang. Composition\nKills: A Case Study of Email Sender Authentication. In\n29th USENIX Security Symposium (USENIX Security\n20), pages 2183–2199. USENIX Association, August\n2020. https://www.usenix.org/conference/usen\nixsecurity20/presentation/chen-jianjun.\n\n[13] Yuting Chen and Zhendong Su. Guided differential\ntesting of certificate validation in SSL/TLS implemen-\ntations. In Proceedings of the 2015 10th Joint Meet-\ning on Foundations of Software Engineering, pages\n793-804, Bergamo Italy, August 2015. ACM. https:\n//doi.org/10.1145/2786805.2786835.\n\n[14] Gynvael Coldwind. Ten thousand traps: ZIP, RAR, etc.,\n2013. https://gynvael.coldwind.pl/?id=523.\n\n[15] Gynvael Coldwind. Ten thousand security pitfalls: The\nZIP file format, 2018. https://gynvael.coldwind\n.pl/?id=682.\n\n[16] David Fifield. Ambiguous Zip Parsing Allows Hid-\ning Add-on Files from Linter and Reviewers, April\n2019. https://www.bamsoftware.com/sec/mozill\na/#1534483.\n\n[17] David Fifield. A better zip bomb. In 13th USENIX\nWorkshop on Offensive Technologies (WOOT 19),\nSanta Clara, CA, August 2019. USENIX Associa-\ntion. https://www.usenix.org/conference/woot\n19/presentation/fifield.\n\n[18] Bahruz Jabiyev, Steven Sprecher, Kaan Onarlioglu, and\nEngin Kirda. T-Reqs: HTTP Request Smuggling with\nDifferential Fuzzing. In Proceedings of the 2021 ACM\nSIGSAC Conference on Computer and Communications\nSecurity, pages 1805–1820, Virtual Event Republic of\nKorea, November 2021. ACM. https://doi.org/10\n.1145/3460120.3485384.\n\n[19] Suman Jana and Vitaly Shmatikov. Abusing file pro-\ncessing in malware detectors for fun and profit. In\n2012 IEEE Symposium on Security and Privacy, pages\n80-94, San Francisco, California, USA, 2012. IEEE.\nhttps://doi.org/10.1109/SP.2012.15.\n\n[20] Jay Freeman. Exploit (& Fix) Android \"Master Key\".\nhttps://www.saurik.com/masterkey1.html.\n\n[21] Dan Kaminsky, Meredith L Patterson, and Len Sas-\nsaman. Pki layer cake: New collision attacks against the\nglobal x. 509 infrastructure. In International Conference\non Financial Cryptography and Data Security, pages\n289-303, Berlin, Heidelberg, 2010. Springer Berlin Hei-\ndelberg. https://doi.org/10.1007/978-3-642-14\n577-3_22.\n\n[22] David Klein and Martin Johns. Parse Me, Baby, One\nMore Time: Bypassing HTML Sanitizer via Parsing\nDifferentials. In 2024 IEEE Symposium on Security and\nPrivacy (SP), pages 203–221, San Francisco, CA, USA,\nMay 2024. IEEE. https://doi.org/10.1109/SP54\n263.2024.00177.\n\n[23] Daniel Komaromy and Lorant Szabo. UnZiploc: A bug\nhunter's journey from 0- click to platform compromise,\n2022. https://labs.taszk.io/articles/post/un\nziploc/.\n\n[24] Donika Mirdita, Haya Shulman, Niklas Vogel, and\nMichael Waidner. The CURE to Vulnerabilities in\nRPKI Validation. In Proceedings 2024 Network and\nDistributed System Security Symposium, San Diego, CA,\nUSA, 2024. Internet Society. https://doi.org/10.1\n4722/ndss.2024.241093.\n\nUSENIX Association\n34th USENIX Security Symposium 445\n\n[25] Jonas Möller, Felix Weißberg, Lukas Pirch, Thorsten\nEisenhofer, and Konrad Rieck. Cross-Language Differ-\nential Testing of JSON Parsers. In Proceedings of the\n19th ACM Asia Conference on Computer and Commu-\nnications Security, pages 1117–1127, Singapore Singa-\npore, July 2024. ACM. https://doi.org/10.1145/\n3634737.3657003.\n\n[26] Gregory R Panakkal. Leaving our zip undone:\nHow to abuse zip to deliver malware apps, 2014.\nhttps://www.virusbulletin.com/virusbulleti\nn/2015/03/paper-leaving-our-zip-undone-how\n-abuse-zip-deliver-malware-apps.\n\n[27] Giancarlo Pellegrino, Davide Balzarotti, Stefan Winter,\nand Neeraj Suri. In the compression Hornet's nest: A\nsecurity study of data compression in network services.\nIn 24th USENIX Security Symposium (USENIX Security\n15), pages 801–816, Washington, D.C., August 2015.\nUSENIX Association. https://www.usenix.org/c\nonference/usenixsecurity15/technical-sessi\nons/presentation/pellegrino.\n\n[28] Theofilos Petsios, Adrian Tang, Salvatore Stolfo, An-\ngelos D. Keromytis, and Suman Jana. NEZHA: Ef-\nficient Domain-Independent Differential Testing. In\n2017 IEEE Symposium on Security and Privacy (SP),\npages 615-632, San Jose, CA, USA, May 2017. IEEE.\nhttps://doi.org/10.1109/SP.2017.27.\n\n[29] PKWARE Inc. APPNOTE.TXT - .ZIP File Format\nSpecification, 2022. https://pkware.cachefly.ne\nt/webdocs/casestudies/APPNOTE.TXT.\n\n[30] Jon Postel. DoD standard Transmission Control Proto-\ncol. RFC 761, January 1980. https://www.rfc-edit\nor.org/info/rfc761.\n\n[31] Gaganjeet Singh Reen and Christian Rossow. DPIFuzz:\nA Differential Fuzzing Framework to Detect DPI Elu-\nsion Strategies for QUIC. In Annual Computer Security\nApplications Conference, pages 332-344, Austin USA,\nDecember 2020. ACM. https://doi.org/10.1145/\n3427228.3427662.\n\n[32] Joshua Reynolds, Adam Bates, and Michael Bailey.\nEquivocal URLs: Understanding the Fragmented Space\nof URL Parser Implementations. In Vijayalakshmi\nAtluri, Roberto Di Pietro, Christian D. Jensen, and\nWeizhi Meng, editors, Computer Security – ESORICS\n2022, volume 13556, pages 166–185, Cham, 2022.\nSpringer Nature Switzerland. https://doi.org/10\n.1007/978-3-031-17143-7_9.\n\n[33] Jost Rossel, Vladislav Mladenov, and Juraj Somorovsky.\nSecurity Analysis of the 3MF Data Format. In Pro-\nceedings of the 26th International Symposium on Re-\n\nsearch in Attacks, Intrusions and Defenses, pages 179–\n194, Hong Kong China, October 2023. ACM. https:\n//doi.org/10.1145/3607199.3607216.\n\n[34] Sergio Alvarez and Thierry Zoller. The Death of AV De-\nfense in Depth? - revisiting Anti-Virus Software, 2008.\n\n[35] Kaiwen Shen, Jianyu Lu, Yaru Yang, Jianjun Chen,\nMingming Zhang, Haixin Duan, Jia Zhang, and Xi-\naofeng Zheng. HDiff: A Semi-automatic Framework\nfor Discovering Semantic Gap Attack in HTTP Imple-\nmentations. In 2022 52nd Annual IEEE/IFIP Interna-\ntional Conference on Dependable Systems and Networks\n(DSN), pages 1-13, Baltimore, MD, USA, June 2022.\nIEEE. https://doi.org/10.1109/DSN53405.2022.\n00014.\n\n[36] Taiga Shirakura, Hirokazu Hasegawa, Yukiko Yam-\naguchi, and Hajime Shimada. Potential Security Risks\nof Internationalized Domain Name Processing for Hy-\nperlink. In 2021 IEEE 45th Annual Computers, Soft-\nware, and Applications Conference (COMPSAC), pages\n1092-1098, Madrid, Spain, July 2021. IEEE. https:\n//doi.org/10.1109/COMPSAC51774.2021.00149.\n\n[37] Suphannee Sivakorn, George Argyros, Kexin Pei, An-\ngelos D. Keromytis, and Suman Jana. HVLearn: Auto-\nmated Black-Box Analysis of Hostname Verification in\nSSL/TLS Implementations. In 2017 IEEE Symposium\non Security and Privacy (SP), pages 521–538, San Jose,\nCA, USA, May 2017. IEEE. https://doi.org/10.1\n109/SP.2017.46.\n\n[38] Snyk. Zip Slip Vulnerability, 2018. https://securi\nty.snyk.io/research/zip-slip-vulnerability.\n\n[39] Daniel Stenberg. My URL isn't your URL, May\n2016. https://daniel.haxx.se/blog/2016/05/11\n/my-url-isnt-your-url/.\n\n[40] Martin Stigge, Henryk Plötz, Wolf Müller, and Jens-\nPeter Redlich. Reversing CRC – Theory and Practice,\n2006.\n\n[41] Cong Tian, Chu Chen, Zhenhua Duan, and Liang Zhao.\nDifferential Testing of Certificate Validation in SSL/TLS\nImplementations: An RFC-guided Approach. ACM\nTransactions on Software Engineering and Methodol-\nogy, 28(4):1-37, October 2019. https://doi.org/10\n.1145/3355048.\n\n[42] Mario Vuksan, Tomislav Pericin, and Brian Karney. Hid-\ning in the Familiar: Steganography and Vulnerabilities\nin Popular Archives Formats, 2010.\n\n[43] Chuhan Wang, Yasuhiro Kuranaga, Yihang Wang, Ming-\nming Zhang, Linkai Zheng, Xiang Li, Jianjun Chen,\n\n446 34th USENIX Security Symposium\nUSENIX Association\n\nHaixin Duan, Yanzhong Lin, and Qingfeng Pan. Break-\nSPF: How Shared Infrastructures Magnify SPF Vul-\nnerabilities Across the Internet. In Proceedings 2024\nNetwork and Distributed System Security Symposium,\nSan Diego, CA, USA, 2024. Internet Society. https:\n//doi.org/10.14722/ndss.2024.23113.\n\n[44] Qi Wang, Jianjun Chen, Zheyu Jiang, Run Guo, Xi-\nmeng Liu, Chao Zhang, and Haixin Duan. Break the\nWall from Bottom: Automated Discovery of Protocol-\nLevel Evasion Vulnerabilities in Web Application Fire-\nwalls. In 2024 IEEE Symposium on Security and Pri-\nvacy (SP), pages 185-202, San Francisco, CA, USA,\nMay 2024. IEEE. https://doi.org/10.1109/SP54\n263.2024.00129.\n\n[45] Xianbo Wang, Wing Cheong Lau, Ronghai Yang, and\nShangcheng Shi. Make Redirection Evil Again: URL\nParser Issues in OAuth, 2019.\n\n[46] Seongil Wi, Trung Tin Nguyen, Jihwan Kim, Ben Stock,\nand Sooel Son. DiffCSP: Finding Browser Bugs in Con-\ntent Security Policy Enforcement through Differential\nTesting. In Proceedings 2023 Network and Distributed\nSystem Security Symposium, San Diego, CA, USA, 2023.\nInternet Society. https://doi.org/10.14722/ndss.\n2023.24200.\n\n[47] Qilang Yang, Dimitrios Damopoulos, and Georgios Por-\ntokalidis. WYSISNWIV: What You Scan Is Not What\nI Visit. In Herbert Bos, Fabian Monrose, and Gre-\ngory Blanc, editors, Research in Attacks, Intrusions, and\nDefenses, volume 9404, pages 317-338, Cham, 2015.\nSpringer International Publishing. https://doi.org/\n10.1007/978-3-319-26362-5_15.\n\n[48] Yufan You, Jianjun Chen, Qi Wang, and Haixin Duan.\nArtifacts for \"My ZIP isn't your ZIP: Identifying and Ex-\nploiting Semantic Gaps Between ZIP Parsers\" (USENIX\nSecurity '25), May 2025. https://doi.org/10.528\n1/zenodo.15526863.\n\n[49] Jiahe Zhang, Jianjun Chen, Qi Wang, Hangyu Zhang,\nChuhan Wang, Jianwei Zhuge, and Haixin Duan. In-\nbox Invasion: Exploiting MIME Ambiguities to Evade\nEmail Attachment Detectors. In Proceedings of the 2024\non ACM SIGSAC Conference on Computer and Commu-\nnications Security, pages 467-481, Salt Lake City UT\nUSA, December 2024. ACM. https://doi.org/10\n.1145/3658644.3670386.\n\n[50] Linkai Zheng, Xiang Li, Chuhan Wang, Run Guo,\nHaixin Duan, Jianjun Chen, Chao Zhang, and Kaiwen\nShen. ReqsMiner: Automated Discovery of CDN\nForwarding Request Inconsistencies and DoS Attacks\nwith Grammar-based Fuzzing. In Proceedings 2024\nNetwork and Distributed System Security Symposium,\n\nSan Diego, CA, USA, 2024. Internet Society. https:\n//doi.org/10.14722/ndss.2024.24031.\n\n[51] Thierry Zoller. Anti-Virus archive bypasses explained,\nApril 2009. https://blog.zoller.lu/2009/04/c\nase-for-av-bypassesevasions.html.\n\n[52] Thierry Zoller. Advisories 2020, 2020.\nhttps://blog.zoller.lu/2020/01/a-new-b\nlog-post-since-last-one-in-2013.html.\n\nA Algorithms\nPseudocode for the algorithms used in Section 4 are listed in\nAlgorithm 1, Algorithm 2, and Algorithm 3.\n\nAlgorithm 1 Directory Hash Computation\nInput: The path to the directory.\nOutput: The hash value of the directory Hash(path).\n1: H ← empty hasher\n2: if path is a symbolic link then\n3: Update H with 'L'\n4: Update H with the link target\n5: else if path is a regular file then\n6: Update H with 'F'\n7: Update H with the file content\n8: else if path is a directory then\n9: Update H with 'D'\n10: C ← empty list\n11: for each entry in the directory do\n12: digest ← Hash(entry)\n13: if digest is empty then\n14: Skip to the next entry // empty directory\n15: end if\n16: He empty hasher\n17: if entry has special characters in base name then\n18: // Ignore inconsistent special characters\n19: Update He with 'S'\n20: else\n21: Update He with 'N'\n22: Update He with the base name of entry\n23: end if\n24: Update He with digest\n25: Insert He.finalize() into C\n26: end for\n27: if C is empty then\n28: return empty\n29: end if\n30: Sort C alphabetically // entry order does not matter\n31: for each digest in C do\n32: Update H with digest\n33: end for\n34: end if\n35: return H.finalize()\n\nUSENIX Association\n34th USENIX Security Symposium 447\n\nAlgorithm 2 Interesting Sample Detection\nInput: Parser outputs O corresponding to the input sample.\nOutput: Whether the sample is interesting. The sample is\ninserted into the corpus if it is interesting. Old samples\ncovered by the new sample are removed from the corpus.\n1: ok ← {parser | O(parser) is not failure}\n2: incons ← {(p,q) ∈ ok² | Hash(O(p)) ≠ Hash(O(q))}\n3: for each s in the corpus do\n4: if ok ⊆ s.ok and incons ⊆ s.incons then\n5: return false\n6: end if\n7: if ok ⊇ s.ok and incons ⊇ s.incons then\n8: Remove s from the corpus\n9: end if\n10: end for\n11: Insert the sample and (ok, incons) into the corpus\n12: return true\n\nAlgorithm 3 Fuzzing With UCB-Based Mutation Selection\nInput: K mutation strategies, batch size B, UCB weight de-\ncaying rate α, softmax temperature β.\nOutput: A corpus of interesting ZIP file samples.\n1: Initialize R and N as arrays of K zeros // reward & count\n2: loop\n3: for i ← 1 to K do\n4: R(i) ← α ⋅ R(i) // decay weights\n5: N(i) ← α ⋅ N(i)\n6: end for\n7: n ← max (∑K\ni=1 N(i), 1) // max(, 1) to avoid ln 0\n8: wi ← Ri / max(N(i),1) + √2ln n / max(N(i),1) // avoid div by 0\n9: σ(W)i ← eβwi / ∑K\nj=1 eβwj // apply softmax to UCB\n10: I ← empty list\n11: for i ← 1 to B do\n12: Select a seed s from the corpus\n13: M ← empty list\n14: loop\n15: m ← a random mutation with weights σ(w)\n16: s ← mutate s by strategy m\n17: Insert m into M\n18: Break loop with 50% probability\n19: end loop\n20: Insert (s, M) into I\n21: end for\n22: Test all inputs I against every parser in parallel\n23: for each (s, M) in I do\n24: for each m in M do\n25: if sample s is detected as interesting then\n26: R(m) ← R(m) + |M|\n27: end if\n28: N(m) ← N(m) + |M|\n29: end for\n30: end for\n31: end loop\n\n448 34th USENIX Security Symposium\nB Tested Parsers\nWe tested the ZIP parsers listed in Table 3. Asterisks are used\nto mark parsers that are provided as a built-in feature of the\nprogramming language, such as standard libraries.\n\nC Parser Inconsistency Table\nTable 4 provides the number of inconsistency types between\nZIP parser pairs. The numbers could be inaccurate when com-\nparing a standard mode parser with a streaming mode parser,\nbecause test samples for other ambiguity types, especially\nthose in the ZIP structure positioning category, might cause\ninconsistencies due to different parsing modes. The complete\nlist of inconsistency types can be found in the artifacts.\n\nUSENIX Association\n\nTable 3: Tested ZIP parsers. GitHub stargazer counts were retrieved on June 12, 2025.\n\n| # | Name (API) | Language (*built-in) | Version | GitHub Star |\n|---|---|---|---|---|\n| 1 | Info-ZIP | C | 6.0 | - |\n| 2 | 7-Zip | C++ | 24.08 | 1.5k |\n| 3 | p7zip | C++ | 16.02 | - |\n| 4 | WinRAR | C++ | 7.01 | - |\n| 5 | Zip-Ada | Ada | 59 | 28 |\n| 6 | go-unarr | C | 0.2.4 | 292 |\n| 7 | libarchive | C | 3.7.7 | 3.2k |\n| 8 | libzip | C | 1.10.1 | 918 |\n| 9 | minizip | C | 1.3.1 | 6.2k |\n| 10 | minizip-ng | C | 4.0.8 | 1.3k |\n| 11 | zip | C | 0.3.2 | 1.5k |\n| 12 | zziplib | C | 0.13.78 | 68 |\n| 13 | DotNetZip | C# | 1.16.0 | 550 |\n| 14 | SharpCompress | C# | 0.38.0 | 2.4k |\n| 15 | SharpZipLib | C# | 1.4.2 | 3.8k |\n| 16 | System.IO.Compression | C#* | 9.0.0 | - |\n| 17 | Android libziparchive | C++ | 34.0.5 | - |\n| 18 | POCO | C++ | 1.13.3 | 9k |\n| 19 | std.zip | D* | 2.109.1 | - |\n| 20 | archive | Dart | 3.6.1 | 445 |\n| 21 | zip | Erlang* | 27.1.2.0 | - |\n| 22 | archive/zip | Go* | 1.22.3 | - |\n| 23 | zip | Haskell | 2.1.0 | 84 |\n| 24 | zip-archive | Haskell | 0.4.3.2 | 46 |\n| 25 | Commons Compress (stream) | Java | 1.27.1 | 365 |\n| 26 | Commons Compress (ZipFile) | Java | 1.27.1 | 365 |\n| 27 | java.util.zip.ZipFile | Java* | 21.0.5 | - |\n| 28 | java.util.zip.ZipInputStream | Java* | 21.0.5 | - |\n| 29 | zip4j (ZipFile) | Java | 2.11.5 | 2.2k |\n| 30 | zip4j (ZipInputStream) | Java | 2.11.5 | 2.2k |\n| 31 | @ronomon/zip | JavaScript | 1.12.0 | 262 |\n| 32 | adm-zip | JavaScript | 0.5.16 | 2.1k |\n| 33 | decompress-zip | JavaScript | 0.3.3 | 102 |\n| 34 | jszip | JavaScript | 3.10.1 | 10k |\n| 35 | node-stream-zip | JavaScript | 1.15.0 | 462 |\n| 36 | unzipper (Extract) | JavaScript | 0.12.3 | 458 |\n| 37 | unzipper (Open) | JavaScript | 0.12.3 | 458 |\n| 38 | yauzl | JavaScript | 2.10.0 | 766 |\n| 39 | yauzl | JavaScript | 3.2.0 | 766 |\n| 40 | zip.js | JavaScript | 2.7.53 | 3.6k |\n| 41 | PharData | PHP* | 8.3.13 | - |\n| 42 | phpzip | PHP | 4.0.2 | 495 |\n| 43 | paszlib | Pascal* | 3.2.2 | - |\n| 44 | Archive::Zip | Perl | 1.68 | 16 |\n| 45 | zipfile | Python* | 3.13.0 | - |\n| 46 | file/unzip | Racket* | 8.15 | - |\n| 47 | rubyzip (File) | Ruby | 2.3.2 | 1.4k |\n| 48 | rubyzip (InputStream) | Ruby | 2.3.2 | 1.4k |\n| 49 | zip | Rust | 2.2.0 | 725 |\n| 50 | ZIP Foundation | Swift | 0.9.19 | 2.5k |\n\nUSENIX Association\n34th USENIX Security Symposium 449\n\nTable 4: Number of inconsistency types between ZIP parser pairs. The row and column headers correspond to the parser\nnumbers in Table 3. The internal cells are the numbers of inconsistency types between parser pairs.\n\n|   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 |\n|---|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|\n| 1 | - | 5 | 6 | 6 | 4 | 6 | 5 | 6 | 7 | 4 | 7 | 6 | 3 | 6 | 5 | 4 | 4 | 7 | 6 | 6 | 4 | 4 | 8 | 6 | 5 | 5 | 4 | 5 | 6 | 6 | 1 | 7 | 5 | 5 | 5 | 7 | 5 | 6 | 7 | 6 | 7 | 6 | 7 | 6 | 4 | 5 | 5 | 6 | 4 | 5 |\n| 2 | 5 | - | 2 | 8 | 6 | 8 | 7 | 7 | 9 | 6 | 8 | 9 | 7 | 6 | 8 | 7 | 6 | 4 | 6 | 6 | 7 | 6 | 8 | 5 | 5 | 7 | 4 | 3 | 8 | 6 | 1 | 10 | 7 | 7 | 8 | 7 | 8 | 8 | 8 | 7 | 9 | 9 | 8 | 7 | 7 | 4 | 8 | 6 | 7 | 6 |\n| 3 | 6 | 2 | - | 7 | 6 | 8 | 7 | 8 | 7 | 7 | 8 | 8 | 7 | 6 | 9 | 7 | 7 | 4 | 6 | 7 | 7 | 5 | 9 | 5 | 6 | 8 | 5 | 4 | 9 | 5 | 1 | 10 | 7 | 6 | 7 | 7 | 8 | 7 | 8 | 8 | 8 | 7 | 6 | 5 | 4 | 8 | 6 | 7 | 6 |\n| 4 | 6 | 8 | 7 | - | 8 | 10 | 8 | 10 | 8 | 8 | 9 | 10 | 8 | 11 | 7 | 9 | 9 | 10 | 10 | 11 | 10 | 9 | 11 | 10 | 10 | 8 | 8 | 11 | 9 | 10 | 3 | 9 | 9 | 8 | 8 | 10 | 10 | 9 | 9 | 10 | 11 | 9 | 11 | 9 | 7 | 11 | 9 | 10 | 9 | 9 |\n| 5 | 4 | 6 | 6 | 8 | - | 11 | 8 | 11 | 7 | 8 | 9 | 8 | 8 | 9 | 5 | 8 | 6 | 6 | 9 | 10 | 7 | 7 | 13 | 6 | 9 | 8 | 6 | 7 | 8 | 6 | 2 | 8 | 9 | 8 | 7 | 7 | 9 | 10 | 10 | 9 | 10 | 8 | 7 | 9 | 6 | 6 | 7 | 8 | 7 | 8 |\n| 6 | 6 | 8 | 8 | 10 | 11 | - | 8 | 10 | 10 | 6 | 5 | 9 | 6 | 12 | 7 | 8 | 7 | 11 | 8 | 8 | 9 | 8 | 11 | 8 | 12 | 9 | 9 | 12 | 4 | 12 | 2 | 8 | 9 | 9 | 8 | 12 | 7 | 5 | 5 | 9 | 8 | 7 | 10 | 10 | 9 | 12 | 8 | 10 | 9 | 8 |\n| 7 | 5 | 7 | 7 | 8 | 8 | 8 | - | 9 | 7 | 4 | 6 | 9 | 7 | 9 | 6 | 6 | 8 | 8 | 6 | 6 | 9 | 7 | 10 | 8 | 9 | 5 | 4 | 9 | 7 | 9 | 1 | 9 | 8 | 5 | 6 | 10 | 8 | 5 | 5 | 8 | 10 | 7 | 10 | 9 | 5 | 9 | 8 | 8 | 8 | 9 |\n| 8 | 6 | 7 | 8 | 10 | 11 | 10 | 9 | - | 11 | 10 | 7 | 9 | 8 | 10 | 8 | 8 | 8 | 10 | 5 | 9 | 8 | 7 | 7 | 7 | 11 | 10 | 7 | 9 | 9 | 10 | 2 | 9 | 9 | 9 | 9 | 10 | 8 | 8 | 6 | 9 | 8 | 6 | 9 | 10 | 8 | 9 | 9 | 10 | 8 | 8 |\n| 9 | 7 | 9 | 7 | 8 | 7 | 10 | 7 | 11 | - | 8 | 9 | 9 | 7 | 11 | 4 | 9 | 7 | 9 | 8 | 10 | 9 | 9 | 12 | 7 | 10 | 8 | 7 | 10 | 7 | 9 | 2 | 9 | 9 | 9 | 8 | 10 | 9 | 10 | 10 | 10 | 10 | 9 | 10 | 9 | 8 | 10 | 8 | 10 | 9 | 9 |\n| 10 | 4 | 6 | 7 | 8 | 8 | 6 | 4 | 10 | 8 | - | 4 | 6 | 5 | 9 | 5 | 5 | 6 | 8 | 7 | 7 | 8 | 4 | 8 | 7 | 8 | 5 | 3 | 8 | 4 | 8 | 2 | 7 | 6 | 6 | 6 | 9 | 6 | 4 | 4 | 7 | 7 | 7 | 10 | 7 | 6 | 8 | 8 | 8 | 7 | 7 |\n| 11 | 7 | 8 | 8 | 9 | 9 | 5 | 6 | 7 | 9 | 4 | - | 6 | 5 | 11 | 4 | 4 | 5 | 9 | 5 | 7 | 7 | 6 | 7 | 8 | 10 | 7 | 6 | 10 | 3 | 10 | 2 | 6 | 6 | 6 | 6 | 10 | 5 | 4 | 3 | 5 | 7 | 5 | 8 | 7 | 7 | 10 | 7 | 10 | 6 | 5 |\n| 12 | 6 | 9 | 8 | 10 | 8 | 9 | 9 | 9 | 9 | 6 | 6 | - | 4 | 10 | 6 | 5 | 3 | 7 | 7 | 10 | 8 | 6 | 9 | 6 | 11 | 9 | 5 | 9 | 7 | 10 | 2 | 5 | 6 | 9 | 5 | 10 | 6 | 7 | 8 | 6 | 3 | 5 | 9 | 8 | 7 | 8 | 8 | 10 | 6 | 5 |\n| 13 | 3 | 7 | 7 | 8 | 8 | 6 | 7 | 8 | 7 | 5 | 5 | 4 | - | 7 | 5 | 3 | 5 | 5 | 6 | 7 | 6 | 4 | 7 | 5 | 9 | 8 | 3 | 6 | 6 | 8 | 1 | 6 | 4 | 6 | 4 | 7 | 5 | 6 | 6 | 6 | 4 | 6 | 7 | 6 | 6 | 6 | 6 | 7 | 7 | 4 |\n| 14 | 6 | 6 | 6 | 11 | 9 | 12 | 9 | 10 | 11 | 10 | 7 | 8 | 7 | - | 8 | 5 | 10 | 11 | 8 | 9 | 12 | 2 | 8 | 11 | 7 | 5 | 10 | 7 | 1 | 12 | 8 | 8 | 7 | 4 | 8 | 11 | 11 | 10 | 9 | 10 | 9 | 11 | 9 | 5 | 9 | 7 | 10 | 9 |\n| 15 | 5 | 8 | 9 | 7 | 5 | 7 | 6 | 8 | 4 | 5 | 4 | 6 | 5 | 8 | - | 4 | 6 | 6 | 5 | 6 | 7 | 5 | 7 | 5 | 9 | 5 | 3 | 7 | 7 | 7 | 1 | 6 | 6 | 7 | 3 | 7 | 4 | 8 | 7 | 7 | 6 | 5 | 5 | 5 | 6 | 6 | 7 | 8 | 4 | 5 |\n| 16 | 4 | 6 | 6 | 5 | 6 | 7 | 5 | 7 | 5 | 9 | 5 | 3 | 7 | 7 | - | 3 | 7 | 6 | 9 | 6 | 4 | 8 | 4 | 10 | 8 | 3 | 7 | 5 | 9 | 1 | 6 | 4 | 5 | 4 | 9 | 1 | 4 | 5 | 5 | 4 | 5 | 8 | 6 | 6 | 8 | 6 | 9 | 6 | 5 |\n| 17 | 4 | 6 | 7 | 9 | 6 | 7 | 8 | 8 | 7 | 6 | 5 | 3 | 5 | 8 | 6 | 3 | - | 7 | 3 | 8 | 3 | 3 | 7 | 6 | 9 | 8 | 5 | 6 | 4 | 7 | 1 | 6 | 4 | 6 | 5 | 8 | 3 | 5 | 5 | 6 | 3 | 3 | 5 | 7 | 6 | 7 | 4 | 8 | 6 | 2 |\n| 18 | 7 | 4 | 4 | 10 | 6 | 11 | 8 | 10 | 9 | 8 | 9 | 7 | 5 | 5 | 6 | 7 | 7 | 8 | - | 8 | 11 | 6 | 6 | 12 | 4 | 5 | 10 | 7 | 2 | 8 | 2 | 2 | 9 | 8 | 8 | 8 | 4 | 8 | 10 | 10 | 9 | 7 | 8 | 6 | 8 | 6 | 2 | 7 | 3 | 7 | 7 |\n| 19 | 6 | 6 | 6 | 10 | 9 | 8 | 6 | 5 | 8 | 7 | 5 | 7 | 6 | 10 | 5 | 6 | 3 | 8 | - | 5 | 4 | 5 | 5 | 5 | 10 | 8 | 4 | 8 | 5 | 9 | 2 | 8 | 7 | 9 | 6 | 9 | 6 | 7 | 5 | 9 | 4 | 5 | 6 | 8 | 6 | 8 | 6 | 10 | 7 | 5 |\n| 20 | 6 | 6 | 7 | 11 | 10 | 8 | 6 | 9 | 10 | 7 | 7 | 10 | 7 | 11 | 6 | 9 | 8 | 11 | 5 | 10 | - | 9 | 9 | 9 | 10 | 9 | 8 | 11 | 5 | 11 | 0 | 9 | 8 | 10 | 5 | 11 | 9 | 8 | 7 | 10 | 11 | 10 | 10 | 10 | 10 | 12 | 8 | 10 | 10 | 8 |\n| 21 | 4 | 7 | 7 | 10 | 7 | 9 | 9 | 8 | 9 | 8 | 7 | 8 | 6 | 8 | 7 | 6 | 3 | 6 | 4 | 10 | 9 | - | 7 | 9 | 6 | 10 | 10 | 8 | 7 | 6 | 8 | 1 | 9 | 9 | 10 | 6 | 8 | 7 | 7 | 7 | 8 | 6 | 5 | 6 | 10 | 7 | 6 | 5 | 8 | 6 | 5 |\n| 22 | 4 | 6 | 5 | 9 | 7 | 8 | 7 | 7 | 9 | 4 | 6 | 6 | 4 | 9 | 5 | 4 | 3 | 6 | 5 | 9 | 9 | 7 | - | 8 | 5 | 9 | 8 | 3 | 7 | 6 | 7 | 2 | 7 | 6 | 6 | 7 | 10 | 5 | 5 | 6 | 7 | 5 | 6 | 7 | 5 | 6 | 7 | 8 | 10 | 3 | 3 |\n| 23 | 8 | 8 | 9 | 11 | 13 | 11 | 10 | 7 | 12 | 8 | 7 | 9 | 7 | 12 | 7 | 8 | 7 | 12 | 5 | 9 | 9 | 8 | 8 | - | 8 | 9 | 6 | 12 | 9 | 13 | 3 | 9 | 8 | 9 | 10 | 12 | 7 | 8 | 7 | 9 | 7 | 7 | 12 | 10 | 8 | 12 | 11 | 12 | 8 | 8 |\n| 24 | 6 | 5 | 5 | 10 | 6 | 8 | 8 | 7 | 7 | 7 | 8 | 6 | 5 | 2 | 5 | 4 | 6 | 4 | 5 | 9 | 8 | 5 | 8 | - | 5 | 9 | 4 | 3 | 8 | 4 | 1 | 9 | 5 | 6 | 5 | 5 | 4 | 9 | 1 | 4 | 5 | 5 | 4 | 5 | 8 | 6 | 6 | 8 | 6 | 9 | 6 | 5 |\n| 25 | 5 | 5 | 6 | 10 | 9 | 12 | 9 | 11 | 10 | 8 | 10 | 11 | 9 | 8 | 9 | 10 | 9 | 5 | 10 | 10 | 9 | 13 | 5 | - | 9 | 10 | 4 | 9 | 3 | 1 | 10 | 10 | 10 | 8 | 7 | 11 | 10 | 10 | 11 | 11 | 10 | 10 | 12 | 9 | 5 | 9 | 3 | 9 | 11 |\n| 26 | 5 | 7 | 8 | 8 | 9 | 5 | 10 | 8 | 5 | 7 | 9 | 8 | 11 | 5 | 8 | 8 | 10 | 8 | 9 | 9 | 9 | 5 | - | 5 | 11 | 7 | 10 | 1 | 8 | 8 | 6 | 8 | 9 | 8 | 7 | 7 | 8 | 10 | 7 | 11 | 8 | 6 | 11 | 10 | 9 | 7 | 10 |\n| 27 | 4 | 4 | 5 | 8 | 6 | 9 | 4 | 7 | 7 | 3 | 6 | 5 | 3 | 7 | 3 | 3 | 5 | 7 | 4 | 8 | 8 | 3 | 6 | 4 | 10 | 5 | 7 | - | 7 | 8 | 0 | 8 | 3 | 4 | 6 | 10 | 4 | 7 | 7 | 7 | 5 | 5 | 8 | 4 | 3 | 7 | 8 | 9 | 5 | 5 |\n| 28 | 5 | 3 | 4 | 11 | 7 | 12 | 9 | 9 | 10 | 8 | 10 | 9 | 6 | 5 | 7 | 7 | 6 | 2 | 8 | 11 | 7 | 7 | 12 | 3 | 4 | 11 | 7 | 9 | 10 | 1 | 11 | - | 8 | 9 | 7 | 7 | 8 | 11 | 11 | 10 | 8 | 8 | 7 | 10 | 6 | 1 | 8 | 2 | 8 | 8 |\n| 29 | 6 | 8 | 9 | 9 | 8 | 4 | 7 | 9 | 7 | 4 | 3 | 7 | 6 | 10 | 7 | 5 | 4 | 8 | 5 | 5 | 6 | 6 | 9 | 8 | 9 | 7 | 7 | 9 | 9 | - | 2 | 7 | 6 | 8 | 5 | 8 | 5 | 4 | 2 | 7 | 7 | 5 | 6 | 8 | 8 | 9 | 5 | 8 | 8 | 5 |\n| 30 | 6 | 6 | 5 | 10 | 6 | 12 | 9 | 10 | 9 | 8 | 10 | 10 | 8 | 7 | 7 | 9 | 7 | 2 | 9 | 11 | 8 | 7 | 13 | 4 | 3 | 10 | 8 | 1 | 9 | 2 | - | 10 | 9 | 10 | 8 | 7 | 10 | 11 | 11 | 11 | 10 | 9 | 7 | 10 | 8 | 2 | 8 | 2 | 7 | 9 |\n| 31 | 1 | 1 | 1 | 3 | 2 | 2 | 1 | 2 | 2 | 2 | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 2 | 2 | 3 | 1 | 1 | 1 | 0 | 0 | 2 | 2 | 3 | 1 | - | 1 | 1 | 1 | 2 | 1 | 2 | 2 | 0 | 2 | 2 | 3 | 1 | 1 | 1 | 1 | 1 | 1 |\n| 32 | 7 | 10 | 10 | 9 | 8 | 8 | 9 | 9 | 9 | 7 | 6 | 5 | 6 | 12 | 6 | 6 | 6 | 9 | 8 | 9 | 9 | 7 | 9 | 9 | 10 | 8 | 8 | 11 | 7 | 10 | 3 | 1 | - | 7 | 8 | 5 | 9 | 7 | 7 | 7 | 7 | 6 | 6 | 10 | 8 | 9 | 11 | 9 | 11 | 7 | 6 |\n| 33 | 5 | 7 | 7 | 9 | 9 | 9 | 8 | 9 | 9 | 6 | 6 | 6 | 4 | 8 | 6 | 4 | 4 | 8 | 7 | 8 | 9 | 6 | 8 | 5 | 10 | 8 | 3 | 8 | 6 | 9 | 1 | 7 | - | 6 | 6 | 10 | 4 | 7 | 7 | 6 | 6 | 7 | 9 | 7 | 7 | 9 | 8 | 10 | 7 | 6 |\n| 34 | 5 | 7 | 6 | 8 | 8 | 9 | 5 | 9 | 9 | 6 | 6 | 9 | 6 | 8 | 7 | 5 | 6 | 8 | 9 | 10 | 10 | 6 | 9 | 6 | 10 | 6 | 4 | 9 | 8 | 10 | 1 | 8 | 6 | 8 | - | 8 | 11 | 7 | 7 | 7 | 7 | 10 | 7 | 10 | 7 | 5 | 9 | 10 | 10 | 7 | 8 |\n| 35 | 5 | 8 | 7 | 8 | 7 | 8 | 6 | 9 | 8 | 6 | 6 | 5 | 4 | 7 | 3 | 4 | 5 | 8 | 6 | 5 | 6 | 7 | 10 | 5 | 8 | 8 | 6 | 7 | 5 | 8 | 1 | 5 | 6 | 8 | 7 | - | 5 | 6 | 7 | 5 | 5 | 7 | 5 | 7 | 8 | 7 | 10 | 6 | 4 |\n| 36 | 7 | 7 | 7 | 10 | 7 | 12 | 10 | 10 | 10 | 9 | 10 | 10 | 7 | 4 | 7 | 9 | 8 | 4 | 9 | 11 | 8 | 10 | 12 | 5 | 7 | 9 | 10 | 7 | 8 | 7 | 2 | 9 | 10 | 1 | 7 | 9 | - | 10 | 10 | 11 | 10 | 9 | 9 | 11 | 9 | 6 | 10 | 7 | 9 | 10 |\n| 37 | 5 | 8 | 8 | 10 | 9 | 7 | 8 | 8 | 9 | 6 | 5 | 6 | 5 | 8 | 4 | 1 | 3 | 8 | 6 | 9 | 7 | 5 | 7 | 4 | 11 | 8 | 4 | 8 | 5 | 10 | 1 | 7 | 4 | 7 | 5 | 9 | 10 | - | 7 | 5 | 6 | 7 | 5 | 7 | 5 | 7 | 8 | 7 | 10 | 6 | 4 |\n| 38 | 6 | 8 | 7 | 9 | 10 | 5 | 5 | 8 | 10 | 4 | 4 | 7 | 6 | 11 | 8 | 4 | 5 | 10 | 7 | 8 | 7 | 5 | 8 | 9 | 10 | 7 | 7 | 11 | 2 | 7 | 7 | 7 | 8 | 10 | 5 | 1 | 7 | - | 6 | 7 | 4 | 7 | 7 | 7 | 11 | 8 | 9 | 6 | 6 | 7 |\n| 39 | 7 | 8 | 8 | 9 | 10 | 5 | 5 | 6 | 10 | 4 | 3 | 8 | 6 | 11 | 7 | 5 | 5 | 10 | 5 | 7 | 7 | 6 | 7 | 9 | 10 | 6 | 7 | 11 | 2 | 7 | 7 | 7 | 8 | 10 | 6 | 1 | 7 | 6 | - | 7 | 4 | 7 | 7 | 7 | 11 | 8 | 9 | 6 | 6 | 7 |\n| 40 | 6 | 7 | 8 | 10 | 9 | 9 | 8 | 9 | 10 | 7 | 5 | 6 | 6 | 10 | 7 | 5 | 6 | 9 | 9 | 10 | 8 | 7 | 9 | 7 | 11 | 8 | 7 | 10 | 7 | 11 | 0 | 7 | 6 | 7 | 11 | 7 | 7 | 6 | 7 | - | 8 | 6 | 9 | 8 | 8 | 10 | 8 | 11 | 6 | 7 |\n| 41 | 7 | 9 | 8 | 11 | 10 | 8 | 10 | 8 | 10 | 7 | 7 | 3 | 4 | 9 | 6 | 4 | 3 | 7 | 4 | 11 | 6 | 5 | 7 | 5 | 11 | 10 | 5 | 8 | 7 | 10 | 2 | 6 | 6 | 10 | 7 | 10 | 5 | 6 | 7 | 8 | - | 6 | 9 | 7 | 8 | 8 | 8 | 10 | 5 | 3 |\n| 42 | 6 | 9 | 8 | 9 | 8 | 7 | 7 | 6 | 9 | 7 | 5 | 5 | 6 | 10 | 5 | 5 | 3 | 8 | 5 | 10 | 5 | 6 | 7 | 7 | 10 | 7 | 5 | 8 | 5 | 9 | 2 | 6 | 7 | 7 | 6 | 9 | 5 | 5 | 4 | 6 | 6 | - | 7 | 6 | 5 | 8 | 7 | 10 | 6 | 4 |\n| 43 | 7 | 8 | 7 | 11 | 7 | 10 | 10 | 9 | 10 | 10 | 8 | 9 | 7 | 9 | 5 | 8 | 5 | 6 | 6 | 10 | 6 | 7 | 12 | 7 | 10 | 11 | 8 | 7 | 6 | 7 | 3 | 10 | 9 | 10 | 7 | 9 | 7 | 8 | 7 | 9 | 9 | 7 | - | 9 | 10 | 7 | 7 | 9 | 6 | 5 |\n| 44 | 6 | 7 | 6 | 9 | 9 | 10 | 9 | 10 | 9 | 7 | 7 | 8 | 6 | 11 | 5 | 6 | 7 | 8 | 8 | 10 | 10 | 5 | 10 | 6 | 12 | 8 | 4 | 10 | 8 | 10 | 1 | 8 | 7 | 7 | 9 | 11 | 5 | 8 | 7 | 8 | 7 | 6 | 9 | 5 | - | 5 | 10 | 9 | 11 | 6 | 6 |\n| 45 | 4 | 7 | 5 | 7 | 6 | 9 | 5 | 8 | 8 | 6 | 7 | 7 | 6 | 9 | 6 | 6 | 6 | 6 | 6 | 10 | 7 | 6 | 8 | 6 | 9 | 6 | 3 | 6 | 8 | 8 | 1 | 9 | 7 | 5 | 7 | 9 | 7 | 7 | 7 | 8 | 8 | 5 | 10 | 5 | - | 6 | 9 | 9 | 8 | 6 |\n| 46 | 5 | 4 | 4 | 11 | 6 | 12 | 9 | 9 | 10 | 8 | 10 | 8 | 6 | 5 | 6 | 8 | 7 | 2 | 8 | 12 | 6 | 7 | 12 | 2 | 5 | 11 | 7 | 1 | 9 | 2 | 1 | 11 | 9 | 9 | 7 | 6 | 8 | 11 | 11 | 10 | 8 | 8 | 7 | 10 | 6 | 8 | - | 8 | 3 | 8 | 8 |\n| 47 | 5 | 8 | 8 | 9 | 7 | 8 | 8 | 9 | 8 | 8 | 7 | 8 | 6 | 9 | 7 | 6 | 4 | 7 | 6 | 8 | 5 | 8 | 11 | 6 | 9 | 10 | 8 | 8 | 5 | 8 | 1 | 9 | 8 | 10 | 5 | 10 | 7 | 8 | 8 | 8 | 7 | 7 | 9 | 9 | 8 | 10 | 8 | 4 | - | 10 | 10 |\n| 48 | 6 | 6 | 6 | 10 | 8 | 10 | 8 | 10 | 10 | 8 | 10 | 10 | 7 | 7 | 8 | 9 | 8 | 3 | 10 | 10 | 8 | 10 | 12 | 5 | 3 | 9 | 9 | 2 | 8 | 2 | 11 | 1 | 10 | 10 | 8 | 7 | 10 | 9 | 9 | 11 | 10 | 10 | 9 | 11 | 9 | 3 | 10 | 10 | - | 10 |\n| 49 | 4 | 7 | 7 | 9 | 7 | 9 | 8 | 8 | 9 | 7 | 6 | 6 | 7 | 10 | 4 | 6 | 6 | 7 | 7 | 10 | 6 | 3 | 8 | 7 | 9 | 7 | 5 | 8 | 8 | 7 | 1 | 7 | 7 | 7 | 6 | 9 | 6 | 6 | 6 | 6 | 5 | 6 | 6 | 6 | 8 | 8 | 8 | 10 | 5 | - |\n| 50 | 5 | 6 | 6 | 9 | 8 | 8 | 9 | 8 | 9 | 7 | 5 | 5 | 4 | 9 | 5 | 5 | 2 | 7 | 5 | 8 | 5 | 3 | 8 | 5 | 11 | 10 | 5 | 8 | 5 | 9 | 1 | 6 | 6 | 8 | 5 | 10 | 4 | 7 | 6 | 7 | 3 | 4 | 5 | 6 | 6 | 8 | 4 | 10 | 5 | - |\n\n450 34th USENIX Security Symposium\nUSENIX Association",
    "est_domaine_public": false,
    "metadata": {}
}